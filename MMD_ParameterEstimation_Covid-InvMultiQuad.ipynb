{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebooks will replicate and build on the results obtained by estimating our custom Covid-19 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.abspath(os.path.join('../BayesFlow')))\n",
    "\n",
    "from functools import partial\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.colors\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from scipy import stats\n",
    "from scipy.stats import binom, nbinom\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Conv1D, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayesflow.networks import InvertibleNetwork, InvariantNetwork\n",
    "from bayesflow.amortizers import SingleModelAmortizer\n",
    "from bayesflow.trainers import ParameterEstimationTrainer\n",
    "from bayesflow.diagnostics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abf_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RERUN_BOOTSTRAP = True\n",
    "RERUN_POWER_ANALYSIS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    \"axes.labelsize\" : 20,\n",
    "    \"xtick.labelsize\" : 16,\n",
    "    \"ytick.labelsize\" : 16,\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Times\"],\n",
    "})\n",
    "\n",
    "FILEFORMAT = 'pdf'\n",
    "DPI = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     23
    ]
   },
   "outputs": [],
   "source": [
    "confirmed_cases_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
    "recovered_cases_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv'\n",
    "dead_cases_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv'\n",
    "\n",
    "\n",
    "confirmed_cases = pd.read_csv(confirmed_cases_url, sep=',')\n",
    "recovered_cases = pd.read_csv(recovered_cases_url, sep=',')\n",
    "dead_cases = pd.read_csv(dead_cases_url, sep=',')\n",
    "\n",
    "\n",
    "date_data_begin = datetime.date(2020,3,1)\n",
    "date_data_end = datetime.date(2020,5,21)\n",
    "\n",
    "\n",
    "format_date = lambda date_py: '{}/{}/{}'.format(date_py.month, date_py.day,\n",
    "                                                 str(date_py.year)[2:4])\n",
    "date_formatted_begin = format_date(date_data_begin)\n",
    "date_formatted_end = format_date(date_data_end)\n",
    "\n",
    "cases_obs =  np.array(\n",
    "    confirmed_cases.loc[confirmed_cases[\"Country/Region\"] == \"Germany\", \n",
    "                        date_formatted_begin:date_formatted_end])[0]\n",
    "recovered_obs =  np.array(\n",
    "    recovered_cases.loc[recovered_cases[\"Country/Region\"] == \"Germany\", \n",
    "                        date_formatted_begin:date_formatted_end])[0]\n",
    "\n",
    "dead_obs =  np.array(\n",
    "    dead_cases.loc[dead_cases[\"Country/Region\"] == \"Germany\", \n",
    "                        date_formatted_begin:date_formatted_end])[0]\n",
    "\n",
    "data_germany = np.stack([cases_obs, recovered_obs, dead_obs]).T\n",
    "data_germany = np.diff(data_germany, axis=0)\n",
    "T_germany = data_germany.shape[0]\n",
    "N_germany = 83e6\n",
    "mean_g = np.mean(data_germany, axis=0)\n",
    "std_g = np.std(data_germany, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epidemiological Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     4,
     43,
     59
    ]
   },
   "outputs": [],
   "source": [
    "alpha_f = (0.7**2)*((1-0.7)/(0.17**2) - (1-0.7))\n",
    "beta_f = alpha_f*(1/0.7 - 1)\n",
    "\n",
    "\n",
    "def prior_sir():\n",
    "    \"\"\"\n",
    "    Implements batch sampling from a stationary prior over the parameters\n",
    "    of the non-stationary SIR model.\n",
    "    \"\"\"\n",
    "    \n",
    "    t1 = np.random.normal(loc=8, scale=3)\n",
    "    t2 = np.random.normal(loc=15, scale=1)\n",
    "    t3 = np.random.normal(loc=22, scale=1)\n",
    "    t4 = np.random.normal(loc=66, scale=1) \n",
    "    delta_t1 = np.random.lognormal(mean=np.log(3), sigma=0.3)\n",
    "    delta_t2 = np.random.lognormal(mean=np.log(3), sigma=0.3)\n",
    "    delta_t3 = np.random.lognormal(mean=np.log(3), sigma=0.3)\n",
    "    delta_t4 = np.random.lognormal(mean=np.log(3), sigma=0.3)\n",
    "    lambd0 = np.random.lognormal(mean=np.log(1.2), sigma=0.5)\n",
    "    lambd1 = np.random.lognormal(mean=np.log(0.6), sigma=0.5)\n",
    "    lambd2 = np.random.lognormal(mean=np.log(0.3), sigma=0.5)\n",
    "    lambd3 = np.random.lognormal(mean=np.log(0.1), sigma=0.5)\n",
    "    lambd4 = np.random.lognormal(mean=np.log(0.1), sigma=0.5)\n",
    "    mu = np.random.lognormal(mean=np.log(1/8), sigma=0.2)\n",
    "    f_i = np.random.beta(a=alpha_f, b=beta_f)\n",
    "    phi_i = stats.vonmises(kappa=0.01).rvs()\n",
    "    f_r = np.random.beta(a=alpha_f, b=beta_f)\n",
    "    phi_r = stats.vonmises(kappa=0.01).rvs()\n",
    "    f_d = np.random.beta(a=alpha_f, b=beta_f)\n",
    "    phi_d = stats.vonmises(kappa=0.01).rvs()\n",
    "    D_i = np.random.lognormal(mean=np.log(8), sigma=0.2)\n",
    "    D_r = np.random.lognormal(mean=np.log(8), sigma=0.2)\n",
    "    D_d = np.random.lognormal(mean=np.log(8), sigma=0.2)\n",
    "    E0 = np.random.gamma(shape=2, scale=30)\n",
    "    scale_I = np.random.gamma(shape=1, scale=5)\n",
    "    scale_R = np.random.gamma(shape=1, scale=5)\n",
    "    scale_D = np.random.gamma(shape=1, scale=5)\n",
    "    return [t1, t2, t3, t4, delta_t1, delta_t2, delta_t3, delta_t4, \n",
    "            lambd0, lambd1, lambd2, lambd3, lambd4, mu, \n",
    "            f_i, phi_i, f_r, phi_r, f_d, phi_d, \n",
    "            D_i, D_r, D_d, E0, scale_I, scale_R, scale_D]\n",
    "\n",
    "\n",
    "def prior_secir():\n",
    "    \"\"\"\n",
    "    Implements batch sampling from a stationary prior over the parameters\n",
    "    of the non-stationary SIR model.\n",
    "    \"\"\"\n",
    "    \n",
    "    alpha = np.random.uniform(low=0.005, high=0.9)\n",
    "    beta = np.random.lognormal(mean=np.log(0.25), sigma=0.3)\n",
    "    gamma = np.random.lognormal(mean=np.log(1/6.5), sigma=0.5)\n",
    "    eta = np.random.lognormal(mean=np.log(1/3.2), sigma=0.3)\n",
    "    theta = np.random.uniform(low=1/14, high=1/3)\n",
    "    delta = np.random.uniform(low=0.01, high=0.3)\n",
    "    d = np.random.uniform(low=1/14, high=1/3)\n",
    "    return [alpha, beta, gamma, eta, theta, delta, d]\n",
    "\n",
    "\n",
    "def calc_lambda_array(sim_lag, lambd0, lambd1, lambd2, lambd3, lambd4, \n",
    "                      t1, t2, t3, t4, delta_t1, delta_t2, delta_t3, delta_t4, T):\n",
    "    \"\"\"Computes the array of time-varying contact rates/transimission probabilities.\"\"\"\n",
    "    \n",
    "    # Array of initial lambdas\n",
    "    lambd0_arr = np.array([lambd0] * (t1+sim_lag))\n",
    "    \n",
    "    # Compute lambd1 array\n",
    "    if delta_t1 == 1:\n",
    "        lambd1_arr = np.array([lambd1] * (t2-t1))\n",
    "    else:\n",
    "        lambd1_arr = np.linspace(lambd0, lambd1, delta_t1)\n",
    "        lambd1_arr = np.append(lambd1_arr, [lambd1] * (t2-t1-delta_t1))\n",
    "        \n",
    "    # Compute lambd2 array\n",
    "    if delta_t2 == 1:\n",
    "        lambd2_arr = np.array([lambd2] * (t3-t2))\n",
    "    else:\n",
    "        lambd2_arr = np.linspace(lambd1, lambd2, delta_t2)\n",
    "        lambd2_arr = np.append(lambd2_arr, [lambd2] * (t3-t2-delta_t2))\n",
    "        \n",
    "    # Compute lambd3 array\n",
    "    if delta_t3 == 1:\n",
    "        lambd3_arr = np.array([lambd3] * (t4-t3))\n",
    "    else:\n",
    "        lambd3_arr = np.linspace(lambd3, lambd4, delta_t3)\n",
    "        lambd3_arr = np.append(lambd3_arr, [lambd3] * (t4-t3-delta_t3))\n",
    "        \n",
    "    # Compute lambd4 array\n",
    "    if delta_t4 == 1:\n",
    "        lambd4_arr = np.array([lambd4] * (T-t4))\n",
    "    else:\n",
    "        lambd4_arr = np.linspace(lambd3, lambd4, delta_t4)\n",
    "        lambd4_arr = np.append(lambd4_arr, [lambd4] * (T-t4-delta_t4))\n",
    "    \n",
    "    return np.r_[lambd0_arr, lambd1_arr, lambd2_arr, lambd3_arr, lambd4_arr]\n",
    "\n",
    "    \n",
    "def non_stationary_SEICR(params_sir, params_secir, N, T, sim_diff=16, observation_model=True):\n",
    "    \"\"\"\n",
    "    Performs a forward simulation from the stationary SIR model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract parameters \n",
    "    t1, t2, t3, t4, delta_t1, delta_t2, delta_t3, delta_t4, lambd0, lambd1, lambd2, lambd3, lambd4, mu, f_i, phi_i, f_r, phi_r, f_d, phi_d, delay_i, delay_r, delay_d, E0, scale_I, scale_R, scale_D = params_sir\n",
    "    alpha, beta, gamma, eta, theta, delta, d = params_secir\n",
    "    \n",
    "    # Round integer parameters\n",
    "    t1, t2, t3, t4 = int(round(t1)), int(round(t2)), int(round(t3)), int(round(t4))\n",
    "    delta_t1, delta_t2, delta_t3, delta_t4 = int(round(delta_t1)), int(round(delta_t2)), int(round(delta_t3)), int(round(delta_t4))\n",
    "    E0 = max(1, np.round(E0)) \n",
    "    delay_i = int(round(delay_i)) \n",
    "    delay_r = int(round(delay_r)) \n",
    "    delay_d = int(round(delay_d)) \n",
    "    \n",
    "    # Impose constraints\n",
    "    assert sim_diff > delay_i\n",
    "    assert sim_diff > delay_r\n",
    "    assert sim_diff > delay_d\n",
    "    assert t1 > 0 and t2 > 0 and t3 > 0 and t4 > 0\n",
    "    assert t1 < t2 < t3 < t4\n",
    "    assert delta_t1 > 0 and delta_t2 > 0 and delta_t3 > 0 and delta_t4 > 0\n",
    "    assert t2 - t1 >= delta_t1 and t3 - t2 >= delta_t2 and t4-t3 >= delta_t3 and T-t4 >= delta_t4\n",
    "\n",
    "    # Calculate lambda arrays\n",
    "    # Lambda0 is the initial contact rate which will be consecutively\n",
    "    # reduced via the government measures\n",
    "    sim_lag = sim_diff - 1\n",
    "    lambd_arr = calc_lambda_array(sim_lag, lambd0, lambd1, lambd2, lambd3, lambd4, \n",
    "                                  t1, t2, t3, t4, delta_t1, delta_t2, delta_t3, delta_t4, T)\n",
    " \n",
    "    # Initial conditions\n",
    "    S, E, C, I, R, D = [N-E0], [E0], [0], [0], [0], [0]\n",
    "    \n",
    "    # Containers\n",
    "    I_news = []\n",
    "    R_news = []\n",
    "    D_news = []\n",
    "    \n",
    "    # Reported new cases\n",
    "    I_data = np.zeros(T)\n",
    "    R_data = np.zeros(T)\n",
    "    D_data = np.zeros(T)\n",
    "    fs_i = np.zeros(T)\n",
    "    fs_r = np.zeros(T)\n",
    "    fs_d = np.zeros(T)\n",
    " \n",
    "    # Simulate T-1 tiemsteps\n",
    "    for t in range(T+sim_lag):\n",
    "        \n",
    "        # Calculate new exposed cases\n",
    "        E_new = lambd_arr[t] * ((C[t] + beta*I[t])/N)*S[t]\n",
    "    \n",
    "        # Remove exposed from susceptible\n",
    "        S_t = S[t] - E_new\n",
    "        \n",
    "        # Calculate current exposed by adding new exposed and\n",
    "        # subtracting the exposed becoming carriers.\n",
    "        E_t = E[t] + E_new - gamma*E[t]\n",
    "        \n",
    "        # Calculate current carriers by adding the new exposed and subtracting\n",
    "        # those who will develop symptoms and become detected and those who\n",
    "        # will go through the disease asymptomatically.\n",
    "        C_t = C[t] + gamma*E[t] - (1-alpha)*eta*C[t] - alpha*theta*C[t]\n",
    "        \n",
    "        # Calculate current infected by adding the symptomatic carriers and \n",
    "        # subtracting the dead and recovered. The newly infected are just the \n",
    "        # carriers who get detected.\n",
    "        I_t = I[t] + (1-alpha)*eta*C[t] - (1-delta)*mu*I[t] - delta*d*I[t]\n",
    "        I_new = (1-alpha)*eta*C[t]\n",
    "        \n",
    "        # Calculate current recovered by adding the symptomatic and asymptomatic\n",
    "        # recovered. The newly recovered are only the detected recovered\n",
    "        R_t = R[t] + alpha*theta*C[t] + (1-delta)*mu*I[t]\n",
    "        R_new = (1-delta)*mu*I[t]\n",
    "        \n",
    "        # Calculate the current dead\n",
    "        D_t = D[t] + delta*d*I[t]\n",
    "        D_new = delta*d*I[t]\n",
    "        \n",
    "        # Ensure some numerical onstraints\n",
    "        S_t = np.clip(S_t, 0, N)\n",
    "        E_t = np.clip(E_t, 0, N)\n",
    "        C_t = np.clip(C_t, 0, N)\n",
    "        I_t = np.clip(I_t, 0, N)\n",
    "        R_t = np.clip(R_t, 0, N)\n",
    "        D_t = np.clip(D_t, 0, N)\n",
    "        \n",
    "        # Keep track of process over time\n",
    "        S.append(S_t)\n",
    "        E.append(E_t)\n",
    "        C.append(C_t)\n",
    "        I.append(I_t)\n",
    "        R.append(R_t)\n",
    "        D.append(D_t)\n",
    "        I_news.append(I_new)\n",
    "        R_news.append(R_new)\n",
    "        D_news.append(D_new)\n",
    "        \n",
    "        # From here, start adding new cases with delay D\n",
    "        # Note, we assume the same delay\n",
    "        if t >= sim_lag:\n",
    "            \n",
    "            # Compute lags and add to data arrays\n",
    "            fs_i[t-sim_lag] = (1-f_i)*(1 - np.abs( np.sin( (np.pi/7) * (t-sim_lag) - 0.5*phi_i)) )\n",
    "            fs_r[t-sim_lag] = (1-f_r)*(1 - np.abs( np.sin( (np.pi/7) * (t-sim_lag) - 0.5*phi_r)) )\n",
    "            fs_d[t-sim_lag] = (1-f_d)*(1 - np.abs( np.sin( (np.pi/7) * (t-sim_lag) - 0.5*phi_d)) )\n",
    "            I_data[t-sim_lag] = I_news[t-delay_i]\n",
    "            R_data[t-sim_lag] = R_news[t-delay_r]\n",
    "            D_data[t-sim_lag] = D_news[t-delay_d]\n",
    "            \n",
    "    # Compute weekly modulation\n",
    "    I_data = (1-fs_i) * I_data\n",
    "    R_data = (1-fs_r) * R_data\n",
    "    D_data = (1-fs_d) * D_data\n",
    "    \n",
    "    # Add noise\n",
    "    I_data = stats.t(df=4, loc=I_data, scale=np.sqrt(I_data)*scale_I).rvs()\n",
    "    R_data = stats.t(df=4, loc=R_data, scale=np.sqrt(R_data)*scale_R).rvs()\n",
    "    D_data = stats.t(df=4, loc=D_data, scale=np.sqrt(D_data)*scale_D).rvs()\n",
    "    \n",
    "    if observation_model:\n",
    "        return np.stack((I_data, R_data, D_data)).T\n",
    "    return np.stack((S, E, I, C, R, D)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def data_generator(n_sim, n_obs, N=None, sim_diff=21, N_min=10000, N_max=70000000):\n",
    "    \"\"\"\n",
    "    Runs the forward model 'batch_size' times by first sampling fromt the prior\n",
    "    theta ~ p(theta) and running x ~ p(x|theta).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Variable size N\n",
    "    if N is None:\n",
    "        N = np.random.randint(N_min, N_max)\n",
    "        \n",
    "    # Generate data\n",
    "    # x is a np.ndarray of shape (batch_size, n_obs, x_dim)\n",
    "    x = []\n",
    "    theta = []\n",
    "    for i in range(n_sim):\n",
    "        \n",
    "        # Reject meaningless simulaitons\n",
    "        x_i = None\n",
    "        while x_i is None:\n",
    "            try:\n",
    "                theta1 = prior_sir()\n",
    "                theta2 = prior_secir()\n",
    "                x_i = non_stationary_SEICR(theta1, theta2, N, n_obs, sim_diff=sim_diff)\n",
    "                x_i = (x_i - mean_g) / std_g\n",
    "            except:\n",
    "                 pass\n",
    "        # Simulate SECIR\n",
    "        x.append(x_i)\n",
    "        theta.append(theta1 + theta2)\n",
    "    x = np.array(x)\n",
    "    theta = np.array(theta)\n",
    "\n",
    "    # Convert to tensor, if specified \n",
    "    return theta.astype(np.float32), x.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names = [r'$t_1$', r'$t_2$', r'$t_3$', r'$t_4$',\n",
    "               r'$\\Delta t_1$', r'$\\Delta t_2$', r'$\\Delta t_3$', r'$\\Delta t_4$',\n",
    "               r'$\\lambda_0$', r'$\\lambda_1$', r'$\\lambda_2$', r'$\\lambda_3$', r'$\\lambda_4$', \n",
    "               r'$\\mu$', r'$f_I$', r'$\\phi_I$',  r'$f_R$', r'$\\phi_R$',  \n",
    "               r'$f_D$', r'$\\phi_D$',\n",
    "               r'$L_I$', r'$L_R$', r'$L_D$', r'$E_0$', r'$\\sigma_I$', r'$\\sigma_R$', r'$\\sigma_D$', \n",
    "               r'$\\alpha$', r'$\\beta$', r'$\\gamma$',\n",
    "               r'$\\eta$', r'$\\theta$', r'$\\delta$', r'$d$']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen = partial(data_generator, N=N_germany, sim_diff=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     13
    ]
   },
   "outputs": [],
   "source": [
    "class MultiConvLayer(tf.keras.Model):\n",
    "    \"\"\"Implements an inception-inspired conv layer using different kernel sizes\"\"\"\n",
    "    def __init__(self, n_filters=32, strides=1):\n",
    "        super(MultiConvLayer, self).__init__()\n",
    "        \n",
    "        self.convs = [\n",
    "            Conv1D(n_filters//2, kernel_size=f, strides=strides, \n",
    "                                   padding='causal', activation='relu', kernel_initializer='glorot_uniform')\n",
    "            for f in range(2, 8)\n",
    "        ]\n",
    "        self.dim_red = Conv1D(n_filters, 1, 1, activation='relu', kernel_initializer='glorot_uniform')\n",
    "        \n",
    "    def call(self, x):\n",
    "        \"\"\"x is a timeseries of dimensions B timestamps, n_features\"\"\"\n",
    "        \n",
    "        out = tf.concat([conv(x) for conv in self.convs], axis=-1)\n",
    "        out = self.dim_red(out)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "class MultiConvNet(tf.keras.Model):\n",
    "    \"\"\"Implements an inception-inspired conv layer using different kernel sizes\"\"\"\n",
    "    def __init__(self, n_layers=3, n_filters=64, strides=1):\n",
    "        super(MultiConvNet, self).__init__()\n",
    "        \n",
    "        self.net = Sequential([\n",
    "            MultiConvLayer(n_filters, strides)\n",
    "            for _ in range(n_layers)\n",
    "        ])\n",
    "        \n",
    "        self.lstm = LSTM(n_filters)\n",
    "        \n",
    "    def call(self, x, **args):\n",
    "        \"\"\"x is a timeseries of dimensions B timestamps, n_features\"\"\"\n",
    "        \n",
    "        out = self.net(x)\n",
    "        out = self.lstm(out)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "class SummaryNet(tf.keras.Model):\n",
    "    def __init__(self, n_summary=192):\n",
    "        super(SummaryNet, self).__init__()\n",
    "        self.net_I = MultiConvNet(n_filters=n_summary//3)\n",
    "        self.net_R = MultiConvNet(n_filters=n_summary//3)\n",
    "        self.net_D = MultiConvNet(n_filters=n_summary//3)\n",
    "    \n",
    "    def call(self, x, **args):\n",
    "        \"\"\"x is a timeseries of dimensions B timestamps, n_features\"\"\"\n",
    "        \n",
    "        x = tf.split(x, 3, axis=-1)\n",
    "        x_i = self.net_I(x[0])\n",
    "        x_r = self.net_R(x[1])\n",
    "        x_d = self.net_D(x[2])\n",
    "        return tf.concat([x_i, x_r, x_d], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_dict={\n",
    "    'n_coupling_layers': 6,\n",
    "    's_args': {\n",
    "        'units': [192, 192, 192],\n",
    "        'activation': 'elu',\n",
    "        'initializer': 'glorot_uniform',\n",
    "    },\n",
    "    't_args': {\n",
    "        'units': [192, 192, 192],\n",
    "        'activation': 'elu',\n",
    "        'initializer': 'glorot_uniform',\n",
    "    },\n",
    "    'alpha': 1.9,\n",
    "    'use_permutation': True,\n",
    "    'use_act_norm': True,\n",
    "    'n_params': len(param_names),\n",
    "}\n",
    "\n",
    "\n",
    "summary_net = SummaryNet()\n",
    "inference_net = InvertibleNetwork(meta_dict)\n",
    "amortizer = SingleModelAmortizer(inference_net, summary_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Networks loaded from export_ckpt/mmd_inverse_quadratic/covid19\\ckpt-50\n"
     ]
    }
   ],
   "source": [
    "starter_learning_rate = 0.0005\n",
    "learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    starter_learning_rate,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.99,\n",
    "    staircase=True\n",
    ")\n",
    "\n",
    "\n",
    "trainer = ParameterEstimationTrainer(\n",
    "    network=amortizer, \n",
    "    generative_model=data_gen,\n",
    "    loss=partial(mmd_kl_loss, kernel = \"inverse_multiquadratic\"),\n",
    "    learning_rate=learning_rate,\n",
    "    checkpoint_path=f'export_ckpt/mmd_inverse_quadratic/covid19',\n",
    "    max_to_keep=1,\n",
    "    skip_checks=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch 1:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch 2:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch 3:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch 4:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch 5:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch 6:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch 7:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch 8:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch 9:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch 10:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch 11:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch 12:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch 13:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch 14:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch 15:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch 16:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch 17:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch 18:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch 19:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch 20:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch 21:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch 22:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch 23:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch 24:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch 25:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch 26:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch 27:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch 28:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch 29:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch 30:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch 31:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch 32:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch 33:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch 34:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch 35:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "losses = trainer.train_online(epochs=38, iterations_per_epoch=1000, batch_size=64, n_obs=T_germany)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, x = trainer._forward_inference(10000, T_germany)\n",
    "s = np.array(trainer.network.summary_net(x))\n",
    "\n",
    "K = 192\n",
    "\n",
    "pca = PCA(K)\n",
    "pca.fit(s)\n",
    "\n",
    "cumsum_explained_variance_ratio = np.cumsum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, K+1), cumsum_explained_variance_ratio, linewidth=4, color=\"dodgerblue\")\n",
    "plt.xlabel(\"Number of PCs\")\n",
    "plt.ylabel(r\"$\\sum R^2$\")\n",
    "plt.ylim(0)\n",
    "plt.xlim(0, 200)\n",
    "plt.plot([0, 192], [1, 1], linestyle=\"dashed\", color=\"grey\", linewidth=2)\n",
    "plt.plot([40, 40], [0, 0.95], linestyle=\"dashed\", color=\"darkgoldenrod\")\n",
    "\n",
    "plt.grid()\n",
    "sns.despine()\n",
    "plt.savefig(f\"inverse_multiquadratic/plots/COVID_PCA_explained_variance.{FILEFORMAT}\", bbox_inches=\"tight\", dpi=DPI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9520579"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumsum_explained_variance_ratio[40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n# Generate data from trainer\\'s generative model\\n_, x = trainer._forward_inference(1000, T_germany)\\ns = np.array(trainer.network.summary_net(x))\\n\\n# Fit PCA to data from trainer\\npca = PCA(2)\\npca.fit(s)\\n\\n\\n# Generate more data from trainer\\'s generative model\\n_, x_star = trainer._forward_inference(1000, T_germany)\\ns_star = trainer.network.summary_net(x_star)\\n\\n# Project all candidate data onto the Principal Components\\ns_star_proj = pca.transform(s_star)\\ns_star_test_proj = pca.transform(s_star_test)\\ns_1_proj = pca.transform(s_1)\\ns_2_proj = pca.transform(s_2)\\ns_3_proj = pca.transform(s_3)\\n\\n\\nS = [s_star_proj, s_star_test_proj, s_1_proj, s_2_proj, s_3proj]\\nTASK_NAMES = [\\'x_star\\', \\'x_star_test\\', \\'x_1\\', \\'x_2\\', \\'x_3\\']\\n\\nDF = (pd.DataFrame(s, \\n                     columns=[r\\'$Proj_{%i}$\\'%i for i in range(1, 3)]) for s in S)\\n\\ndf = pd.concat(DF,\\n              keys=TASK_NAMES,\\n              names=[\\'Model\\', None]\\n              ).reset_index(level=0)\\n\\ng = sns.PairGrid(df, hue=\"Model\", palette=[\\'red\\', \\'orange\\', \\'green\\', \\'blue\\', \\'brown\\'], height=3)\\n\\ng.map_upper(plt.scatter, alpha=0.1)\\ng.map_diag(sns.kdeplot)\\ng.map_lower(sns.kdeplot, alpha=0.50)\\n\\ng.add_legend()\\nplt.setp(g._legend.get_title(), fontsize=16)\\nplt.setp(g._legend.get_texts(), fontsize=14)\\n\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "# Generate data from trainer's generative model\n",
    "_, x = trainer._forward_inference(1000, T_germany)\n",
    "s = np.array(trainer.network.summary_net(x))\n",
    "\n",
    "# Fit PCA to data from trainer\n",
    "pca = PCA(2)\n",
    "pca.fit(s)\n",
    "\n",
    "\n",
    "# Generate more data from trainer's generative model\n",
    "_, x_star = trainer._forward_inference(1000, T_germany)\n",
    "s_star = trainer.network.summary_net(x_star)\n",
    "\n",
    "# Project all candidate data onto the Principal Components\n",
    "s_star_proj = pca.transform(s_star)\n",
    "s_star_test_proj = pca.transform(s_star_test)\n",
    "s_1_proj = pca.transform(s_1)\n",
    "s_2_proj = pca.transform(s_2)\n",
    "s_3_proj = pca.transform(s_3)\n",
    "\n",
    "\n",
    "S = [s_star_proj, s_star_test_proj, s_1_proj, s_2_proj, s_3proj]\n",
    "TASK_NAMES = ['x_star', 'x_star_test', 'x_1', 'x_2', 'x_3']\n",
    "\n",
    "DF = (pd.DataFrame(s, \n",
    "                     columns=[r'$Proj_{%i}$'%i for i in range(1, 3)]) for s in S)\n",
    "\n",
    "df = pd.concat(DF,\n",
    "              keys=TASK_NAMES,\n",
    "              names=['Model', None]\n",
    "              ).reset_index(level=0)\n",
    "\n",
    "g = sns.PairGrid(df, hue=\"Model\", palette=['red', 'orange', 'green', 'blue', 'brown'], height=3)\n",
    "\n",
    "g.map_upper(plt.scatter, alpha=0.1)\n",
    "g.map_diag(sns.kdeplot)\n",
    "g.map_lower(sns.kdeplot, alpha=0.50)\n",
    "\n",
    "g.add_legend()\n",
    "plt.setp(g._legend.get_title(), fontsize=16)\n",
    "plt.setp(g._legend.get_texts(), fontsize=14)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate PCAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n# Generate data from trainer\\'s generative model\\n_, x_star = trainer._forward_inference(1000, T_germany)\\ns_star = trainer.network.summary_net(x_star)\\n\\n# Fit and project all data on separate PCAs based on them\\ns_star_proj = PCA(2).fit_transform(s_star)\\ns_star_test_proj = PCA(2).fit_transform(s_star_test)\\ns_1_proj = PCA(2).fit_transform(s_1)\\ns_2_proj = PCA(2).fit_transform(s_2)\\ns_3_proj = PCA(2).fit_transform(s_3)\\n\\n\\nS = [s_star_proj, s_star_test_proj, s_1_proj, s_2_proj, s_3_proj]\\nTASK_NAMES = [\\'x_star\\', \\'x_star_test\\', \\'x_1\\', \\'x_2\\', \\'x_3\\']\\n\\nDF = (pd.DataFrame(s, \\n                     columns=[r\\'$Proj_{%i}$\\'%i for i in range(1, 3)]) for s in S)\\n\\ndf = pd.concat(DF,\\n              keys=TASK_NAMES,\\n              names=[\\'Model\\', None]\\n              ).reset_index(level=0)\\n\\ng = sns.PairGrid(df, hue=\"Model\", palette=[\\'red\\', \\'orange\\', \\'green\\', \\'blue\\', \\'brown\\'], height=3)\\n\\ng.map_upper(plt.scatter, alpha=0.1)\\ng.map_diag(sns.kdeplot)\\ng.map_lower(sns.kdeplot, alpha=0.50)\\n\\ng.add_legend()\\nplt.setp(g._legend.get_title(), fontsize=16)\\nplt.setp(g._legend.get_texts(), fontsize=14)\\n\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "# Generate data from trainer's generative model\n",
    "_, x_star = trainer._forward_inference(1000, T_germany)\n",
    "s_star = trainer.network.summary_net(x_star)\n",
    "\n",
    "# Fit and project all data on separate PCAs based on them\n",
    "s_star_proj = PCA(2).fit_transform(s_star)\n",
    "s_star_test_proj = PCA(2).fit_transform(s_star_test)\n",
    "s_1_proj = PCA(2).fit_transform(s_1)\n",
    "s_2_proj = PCA(2).fit_transform(s_2)\n",
    "s_3_proj = PCA(2).fit_transform(s_3)\n",
    "\n",
    "\n",
    "S = [s_star_proj, s_star_test_proj, s_1_proj, s_2_proj, s_3_proj]\n",
    "TASK_NAMES = ['x_star', 'x_star_test', 'x_1', 'x_2', 'x_3']\n",
    "\n",
    "DF = (pd.DataFrame(s, \n",
    "                     columns=[r'$Proj_{%i}$'%i for i in range(1, 3)]) for s in S)\n",
    "\n",
    "df = pd.concat(DF,\n",
    "              keys=TASK_NAMES,\n",
    "              names=['Model', None]\n",
    "              ).reset_index(level=0)\n",
    "\n",
    "g = sns.PairGrid(df, hue=\"Model\", palette=['red', 'orange', 'green', 'blue', 'brown'], height=3)\n",
    "\n",
    "g.map_upper(plt.scatter, alpha=0.1)\n",
    "g.map_diag(sns.kdeplot)\n",
    "g.map_lower(sns.kdeplot, alpha=0.50)\n",
    "\n",
    "g.add_legend()\n",
    "plt.setp(g._legend.get_title(), fontsize=16)\n",
    "plt.setp(g._legend.get_texts(), fontsize=14)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('inverse_multiquadratic/data/COVID_model_data/data_model_star_test.pkl', 'rb') as f:\n",
    "    x_star_test = pickle.load(f)['x']\n",
    "with open('inverse_multiquadratic/data/COVID_model_data/data_model_1.pkl', 'rb') as f:\n",
    "    x_1 = pickle.load(f)['x']\n",
    "with open('inverse_multiquadratic/data/COVID_model_data/data_model_2.pkl', 'rb') as f:\n",
    "    x_2 = pickle.load(f)['x']\n",
    "with open('inverse_multiquadratic/data/COVID_model_data/data_model_3.pkl', 'rb') as f:\n",
    "    x_3 = pickle.load(f)['x']\n",
    "\n",
    "_, x_star = trainer._forward_inference(1000, T_germany)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MMD_bootstrap(x_star, x_test, N_BOOTSTRAP_ITERATIONS=10, n_samples_star=1000, n_samples_test=1000):\n",
    "    n_star = x_star.shape[0]\n",
    "    n_test = x_test.shape[0]\n",
    "    \n",
    "    MMD_bootstrap = np.empty(N_BOOTSTRAP_ITERATIONS)\n",
    "\n",
    "    for i in tqdm(range(N_BOOTSTRAP_ITERATIONS)):\n",
    "        idx_star = np.random.randint(0, n_star, size=n_samples_star)\n",
    "        idx_test = np.random.randint(0, n_test, size=n_samples_test)\n",
    "        \n",
    "        x_star_bootstrap = x_star[idx_star]\n",
    "        x_test_bootstrap = x_test[idx_test]\n",
    "        \n",
    "        s_star_bootstrap = np.array(trainer.network.summary_net(x_star_bootstrap))\n",
    "        s_test_bootstrap = np.array(trainer.network.summary_net(x_test_bootstrap))\n",
    "        \n",
    "        MMD_bootstrap[i] = float(maximum_mean_discrepancy(s_star_bootstrap, s_test_bootstrap, squared=False, kernel=\"inverse_multiquadratic\"))\n",
    "        \n",
    "    return MMD_bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_CI(x, ci_area=0.95):\n",
    "    q_lower = round((1.0 - ci_area) / 2, 5)\n",
    "    q_upper = round(1.0 - q_lower, 5)\n",
    "    return np.quantile(x, q_lower), np.quantile(x, q_upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Bootstrap for n_samples_test=1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "813150fca4064adf91aa42cd23763c23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples_star = 1000\n",
    "N_BOOTSTRAP_ITERATIONS = 100\n",
    "\n",
    "for n_samples_test in [1,2,5]:\n",
    "    if RERUN_BOOTSTRAP:\n",
    "        print(f\"Started Bootstrap for n_samples_test={n_samples_test}\")\n",
    "        MMD_star_bootstrap = MMD_bootstrap(x_star, x_star_test, N_BOOTSTRAP_ITERATIONS=N_BOOTSTRAP_ITERATIONS, n_samples_star=n_samples_star, n_samples_test=n_samples_test)\n",
    "        MMD_1_bootstrap    = MMD_bootstrap(x_star, x_1,         N_BOOTSTRAP_ITERATIONS=N_BOOTSTRAP_ITERATIONS, n_samples_star=n_samples_star, n_samples_test=n_samples_test)\n",
    "        MMD_2_bootstrap    = MMD_bootstrap(x_star, x_2,         N_BOOTSTRAP_ITERATIONS=N_BOOTSTRAP_ITERATIONS, n_samples_star=n_samples_star, n_samples_test=n_samples_test)\n",
    "        MMD_3_bootstrap    = MMD_bootstrap(x_star, x_3,         N_BOOTSTRAP_ITERATIONS=N_BOOTSTRAP_ITERATIONS, n_samples_star=n_samples_star, n_samples_test=n_samples_test)\n",
    "\n",
    "        np.save(f\"inverse_multiquadratic/data/MMD_bootstrapping/MMD_star_bootstrap_N{n_samples_test}.npy\", MMD_star_bootstrap)\n",
    "        np.save(f\"inverse_multiquadratic/data/MMD_bootstrapping/MMD_1_bootstrap_N{n_samples_test}.npy\", MMD_1_bootstrap)\n",
    "        np.save(f\"inverse_multiquadratic/data/MMD_bootstrapping/MMD_2_bootstrap_N{n_samples_test}.npy\", MMD_2_bootstrap)\n",
    "        np.save(f\"inverse_multiquadratic/data/MMD_bootstrapping/MMD_3_bootstrap_N{n_samples_test}.npy\", MMD_3_bootstrap)\n",
    "    \n",
    "    MMD_star_bootstrap = np.load(f\"inverse_multiquadratic/data/MMD_bootstrapping/MMD_star_bootstrap_N{n_samples_test}.npy\")\n",
    "    MMD_1_bootstrap = np.load(f\"inverse_multiquadratic/data/MMD_bootstrapping/MMD_1_bootstrap_N{n_samples_test}.npy\")\n",
    "    MMD_2_bootstrap = np.load(f\"inverse_multiquadratic/data/MMD_bootstrapping/MMD_2_bootstrap_N{n_samples_test}.npy\")\n",
    "    MMD_3_bootstrap = np.load(f\"inverse_multiquadratic/data/MMD_bootstrapping/MMD_3_bootstrap_N{n_samples_test}.npy\")\n",
    "    MMDs_bootstrap = [MMD_star_bootstrap, MMD_1_bootstrap, MMD_2_bootstrap, MMD_3_bootstrap]\n",
    "\n",
    "    for i, MMD_b in zip([\"star\", \"1\", \"2\", \"3\"], MMDs_bootstrap):\n",
    "        lower_bound, upper_bound = calculate_CI(MMD_b, ci_area=0.95)\n",
    "        median = np.median(MMD_b)\n",
    "        print(f\"N = {n_samples_test}:   M{i}: {median:.2f} [{lower_bound:.2f}, {upper_bound:.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MMDs = [MMD_star, MMD_1, MMD_2, MMD_3]\n",
    "MMD_bootstraps = [MMD_star_bootstrap, MMD_1_bootstrap, MMD_2_bootstrap, MMD_3_bootstrap]\n",
    "colors = [\"red\", \"firebrick\", \"orange\", \"blue\"]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for i in range(4):\n",
    "    sns.kdeplot(MMD_bootstraps[i], ax=ax, label=f\"M{i}\")\n",
    "    ax.legend()\n",
    "    ax.set_title(r\"$\\widehat{rMMD}$ for 100 bootstraps of $x^*$ and $x_{test}$\")\n",
    "    ax.set_xlabel(r\"$\\widehat{rMMD}$\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power Analysis for $N=1,2,5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen_star = data_gen\n",
    "from covid_models.covid19_ablation_intervention import data_gen as data_gen_1\n",
    "from covid_models.covid19_ablation_observation import data_gen as data_gen_2\n",
    "from covid_models.covid19_ablation_carrier import data_gen as data_gen_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MMD_power_analysis_generic(G_star, N_star, G_test, N_test, summary_network, number_power_simulations, number_H0_simulations=1000, n_obs=None, alpha=.05):\n",
    "    # Calculate MMD_H0: Simulate MMD(A|B) with A~G_star and B~G_star\n",
    "    MMD_H0 = np.empty(number_H0_simulations)\n",
    "    _, x_star = G_star(N_star, n_obs)\n",
    "    s_star = summary_network(x_star)\n",
    "    for i in tqdm(range(number_H0_simulations), desc=\"Compute MMD under H0\"):\n",
    "        _, x_star_prime = G_star(N_test, n_obs)\n",
    "        s_star_prime = summary_network(x_star_prime)\n",
    "        MMD_H0[i] = float(maximum_mean_discrepancy(s_star, s_star_prime, squared=False, kernel=\"inverse_multiquadratic\"))\n",
    "    \n",
    "    \n",
    "    # Simulate data from the test model and compare its MMDs against H0 MMD disto\n",
    "    MMDs_test = np.empty(number_power_simulations)\n",
    "    _, x_star = G_star(N_star, n_obs)\n",
    "    s_star = summary_network(x_star)\n",
    "    for i in tqdm(range(number_power_simulations), desc=\"Simulate data from G_test and compute MMD\"):\n",
    "        _, x_test = G_test(N_test, n_obs)\n",
    "        s_test = summary_network(x_test)\n",
    "        \n",
    "        MMDs_test[i] = float(maximum_mean_discrepancy(s_star, s_test, squared=False, kernel=\"inverse_multiquadratic\"))\n",
    "\n",
    "    MMD_critical = np.quantile(MMD_H0, 1-alpha)    \n",
    "    power = (MMDs_test > MMD_critical).mean()      \n",
    "\n",
    "    return {\"power\" : power,\n",
    "            \"MMD_H0\" : MMD_H0,\n",
    "            \"MMDs_test\" : MMDs_test,\n",
    "            \"MMD_critical\" : MMD_critical,\n",
    "            \"alpha\" : alpha,\n",
    "            \"N\" : N_test\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RERUN_POWER_ANALYSIS:\n",
    "    N_star = 1000\n",
    "    N_test = 1\n",
    "    number_power_simulations = 1000\n",
    "    number_H0_simulations = 1000\n",
    "\n",
    "    models = [1, 2, 3]\n",
    "    for model in models:\n",
    "        print(f\"Power analysis for model {model}\")\n",
    "        data_gen = globals()[f\"data_gen_{model}\"]\n",
    "        power_result = MMD_power_analysis_generic(\n",
    "            G_star = trainer._forward_inference,\n",
    "            N_star = N_star,\n",
    "            G_test = data_gen,\n",
    "            N_test = N_test,\n",
    "            summary_network = trainer.network.summary_net,\n",
    "            number_power_simulations = number_power_simulations,\n",
    "            number_H0_simulations = number_H0_simulations,\n",
    "            n_obs = T_germany\n",
    "            )\n",
    "\n",
    "        with open(f\"inverse_multiquadratic/data/COVID_power/covid_power_N{N_test}_M{model}.pkl\", 'wb') as f:\n",
    "            pickle.dump(power_result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RERUN_POWER_ANALYSIS:\n",
    "    N_star = 1000\n",
    "    N_test = 2\n",
    "    number_power_simulations = 1000\n",
    "    number_H0_simulations = 1000\n",
    "\n",
    "    models = [1, 2, 3]\n",
    "    for model in models:\n",
    "        print(f\"Power analysis for model {model}\")\n",
    "        data_gen = globals()[f\"data_gen_{model}\"]\n",
    "        power_result = MMD_power_analysis_generic(\n",
    "            G_star = trainer._forward_inference,\n",
    "            N_star = N_star,\n",
    "            G_test = data_gen,\n",
    "            N_test = N_test,\n",
    "            summary_network = trainer.network.summary_net,\n",
    "            number_power_simulations = number_power_simulations,\n",
    "            number_H0_simulations = number_H0_simulations,\n",
    "            n_obs = T_germany\n",
    "            )\n",
    "\n",
    "        with open(f\"inverse_multiquadratic/data/COVID_power/covid_power_N{N_test}_M{model}.pkl\", 'wb') as f:\n",
    "            pickle.dump(power_result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RERUN_POWER_ANALYSIS:\n",
    "    N_star = 1000\n",
    "    N_test = 5\n",
    "    number_power_simulations = 1000\n",
    "    number_H0_simulations = 1000\n",
    "\n",
    "    models = [1, 2, 3]\n",
    "    for model in models:\n",
    "        print(f\"Power analysis for model {model}\")\n",
    "        data_gen = globals()[f\"data_gen_{model}\"]\n",
    "        power_result = MMD_power_analysis_generic(\n",
    "            G_star = trainer._forward_inference,\n",
    "            N_star = N_star,\n",
    "            G_test = data_gen,\n",
    "            N_test = N_test,\n",
    "            summary_network = trainer.network.summary_net,\n",
    "            number_power_simulations = number_power_simulations,\n",
    "            number_H0_simulations = number_H0_simulations,\n",
    "            n_obs = T_germany\n",
    "            )\n",
    "\n",
    "        with open(f\"inverse_multiquadratic/data/COVID_power/covid_power_N{N_test}_M{model}.pkl\", 'wb') as f:\n",
    "            pickle.dump(power_result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_area_under_kde(kde_object, x_start, x_end=None, **kwargs):\n",
    "    kde_x, kde_y = kde_object.lines[0].get_data()\n",
    "    if x_end is not None:\n",
    "        plt.fill_between(kde_x, kde_y, where=(kde_x>=x_start) & (kde_x<=x_end), \n",
    "                    interpolate=True, **kwargs)\n",
    "    else:\n",
    "        plt.fill_between(kde_x, kde_y, where=(kde_x>=x_start), \n",
    "                    interpolate=True, **kwargs)\n",
    "\n",
    "\n",
    "def print_powers(N_test, models=[1,2,3], xlims=(None, None)):\n",
    "    H0_color = \"#287D8EFF\"\n",
    "    model_color = \"#55C667FF\"\n",
    "    alpha_color = \"#481567FF\"\n",
    "    \n",
    "    for model in models:\n",
    "        with open(f\"inverse_multiquadratic/data/COVID_power/covid_power_N{N_test}_M{model}.pkl\", \"rb\") as f:\n",
    "            power_result = pickle.load(f)\n",
    "\n",
    "        MMD_H0 = power_result[\"MMD_H0\"]\n",
    "        MMDs_test = power_result[\"MMDs_test\"]\n",
    "        MMD_critical = power_result[\"MMD_critical\"]\n",
    "        \n",
    "\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(8,4))\n",
    "        kde_H0 = sns.kdeplot(MMD_H0, linewidth=3, label=r\"$H_0$\", color=H0_color)\n",
    "        sns.kdeplot(MMD_H0, fill=True, alpha=.12, color = H0_color)\n",
    "        \n",
    "        kde_test = sns.kdeplot(MMDs_test, ax=ax, linewidth=3, label=r\"$\\mathcal{M}_{%d}$\"%model, color=model_color)\n",
    "        sns.kdeplot(MMDs_test, fill=True, alpha=.12, color = model_color)\n",
    "        \n",
    "        fill_area_under_kde(kde_H0, MMD_critical, color=alpha_color, alpha=0.7, label=r\"5\\% rejection area\")\n",
    "        \n",
    "        #ax.set_title(r'Model $\\mathcal{M}_%d, N=%d: 1-\\beta=%.3f$'%(model, N_test, power_result[\"power\"]), fontsize=16)\n",
    "        ax.set_xlabel(r\"$\\widehat{\\mathrm{rMMD}}$\")\n",
    "        ax.set_ylabel(\"\")\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xlim(*xlims)\n",
    "\n",
    "        #ax.legend(fontsize=16)\n",
    "        sns.despine()\n",
    "        plt.savefig(f\"inverse_multiquadratic/plots/COVID_power_N{N_test}_M{model}.{FILEFORMAT}\", bbox_inches=\"tight\")\n",
    "        \n",
    "    # save legend separately\n",
    "    plt.figure(figsize=(0.1,0.1))\n",
    "    plt.gca().set_axis_off()\n",
    "    handles = [mpatches.Patch(facecolor=H0_color, \n",
    "                              #label=r\"$\\hat{p}(\\widehat{\\mathrm{rMMD}}\\,|\\,H_0)$\")\n",
    "                              label = r\"$\\widehat{\\mathrm{rMMD}}$ under $H_0$\"),\n",
    "               mpatches.Patch(facecolor=model_color,\n",
    "                              #label=r\"$\\hat{p}(\\widehat{\\mathrm{rMMD}}\\,|\\,{\\fontfamily{cm}\\selectfont\\mathcal{M}}_j)$\")\n",
    "                              label = r\"$\\widehat{\\mathrm{rMMD}}$ under the (misspecified) model\"),\n",
    "               mpatches.Patch(facecolor=alpha_color, label=r\"$H_0$ rejection area\")]\n",
    "    plt.legend(handles=handles, loc=\"center\", ncol=3, title=\"\" ,fontsize=20, labelspacing=2)\n",
    "\n",
    "    plt.savefig(f\"inverse_multiquadratic/plots/COVID_power_legend.{FILEFORMAT}\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_powers(N_test=1, xlims=(3.6, 3.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_powers(N_test=2, xlims=(2.4, 3.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_powers(N_test=5, xlims=(1.5, 2.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Data w.r.t. $MMD|H_0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed_cases_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
    "recovered_cases_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv'\n",
    "dead_cases_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv'\n",
    "\n",
    "\n",
    "confirmed_cases = pd.read_csv(confirmed_cases_url, sep=',')\n",
    "recovered_cases = pd.read_csv(recovered_cases_url, sep=',')\n",
    "dead_cases = pd.read_csv(dead_cases_url, sep=',')\n",
    "\n",
    "\n",
    "date_data_begin = datetime.date(2020,3,1)\n",
    "date_data_end = datetime.date(2020,5,21)\n",
    "\n",
    "\n",
    "format_date = lambda date_py: '{}/{}/{}'.format(date_py.month, date_py.day,\n",
    "                                                 str(date_py.year)[2:4])\n",
    "date_formatted_begin = format_date(date_data_begin)\n",
    "date_formatted_end = format_date(date_data_end)\n",
    "\n",
    "cases_obs =  np.array(\n",
    "    confirmed_cases.loc[confirmed_cases[\"Country/Region\"] == \"Germany\", \n",
    "                        date_formatted_begin:date_formatted_end])[0]\n",
    "recovered_obs =  np.array(\n",
    "    recovered_cases.loc[recovered_cases[\"Country/Region\"] == \"Germany\", \n",
    "                        date_formatted_begin:date_formatted_end])[0]\n",
    "\n",
    "dead_obs =  np.array(\n",
    "    dead_cases.loc[dead_cases[\"Country/Region\"] == \"Germany\", \n",
    "                        date_formatted_begin:date_formatted_end])[0]\n",
    "\n",
    "data_germany = np.stack([cases_obs, recovered_obs, dead_obs]).T\n",
    "data_germany = np.diff(data_germany, axis=0)\n",
    "T_germany = data_germany.shape[0]\n",
    "N_germany = 83e6\n",
    "mean_g = np.mean(data_germany, axis=0)\n",
    "std_g = np.std(data_germany, axis=0)\n",
    "\n",
    "data_germany_tensor = data_germany[np.newaxis, ...]\n",
    "data_germany_tensor.shape\n",
    "data_germany_standardized = (data_germany_tensor - mean_g) / std_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_obs = T_germany\n",
    "N_star = 1000\n",
    "N_test = 1\n",
    "number_H0_simulations = 10000\n",
    "G_star = data_gen_star\n",
    "summary_network = trainer.network.summary_net\n",
    "\n",
    "# Calculate MMD_H0: Simulate MMD(A|B) with A~G_star and B~G_star\n",
    "MMD_H0 = np.empty(number_H0_simulations)\n",
    "_, x_star = G_star(N_star, n_obs)\n",
    "s_star = summary_network(x_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(number_H0_simulations), desc=\"Compute MMD under H0\"):\n",
    "    _, x_star_prime = G_star(N_test, n_obs)\n",
    "    s_star_prime = summary_network(x_star_prime)\n",
    "    MMD_H0[i] = float(maximum_mean_discrepancy(s_star, s_star_prime, squared=False, kernel=\"inverse_multiquadratic\"))\n",
    "    \n",
    "np.save(\"inverse_multiquadratic/data/COVID_real_world_analysis/MMD_H0_N1.npy\", MMD_H0)\n",
    "np.save(\"inverse_multiquadratic/data/COVID_real_world_analysis/MMD_H0_N1_x_star.npy\", x_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MMD_H0 = np.load(\"inverse_multiquadratic/data/COVID_real_world_analysis/MMD_H0_N1.npy\")\n",
    "x_star = np.load(\"inverse_multiquadratic/data/COVID_real_world_analysis/MMD_H0_N1_x_star.npy\")\n",
    "\n",
    "s_germany_standardized = np.array(trainer.network.summary_net(data_germany_standardized))\n",
    "s_germany_standardized.shape\n",
    "MMD_germany_standardized = float(maximum_mean_discrepancy(s_germany_standardized, s_star, squared=False, kernel=\"inverse_multiquadratic\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_vline_to_kde(x, kde_object, color, **kwargs):\n",
    "    kde_x, kde_y = kde_object.lines[0].get_data()\n",
    "    idx = np.argmin(np.abs(kde_x - x))\n",
    "    plt.plot([x, x], [0, kde_y[idx]], color=color, linewidth=4, **kwargs)\n",
    "    \n",
    "def fill_area_under_kde(kde_object, x_start, x_end=None, **kwargs):\n",
    "    kde_x, kde_y = kde_object.lines[0].get_data()\n",
    "    if x_end is not None:\n",
    "        plt.fill_between(kde_x, kde_y, where=(kde_x>=x_start) & (kde_x<=x_end), \n",
    "                    interpolate=True, **kwargs)\n",
    "    else:\n",
    "        plt.fill_between(kde_x, kde_y, where=(kde_x>=x_start), \n",
    "                    interpolate=True, **kwargs)\n",
    "\n",
    "\n",
    "bw_factor = 1.5\n",
    "plt.figure(figsize=(8, 4))\n",
    "alpha = 0.05\n",
    "H0_color = \"#287D8EFF\"\n",
    "data_germany_color = \"#55C667FF\"\n",
    "alpha_color = \"#481567FF\"\n",
    "\n",
    "kde = sns.kdeplot(MMD_H0, fill=False, linewidth=0, bw_adjust=bw_factor)\n",
    "sns.kdeplot(MMD_H0, fill=True, alpha=.12, color = H0_color, bw_adjust=bw_factor)\n",
    "\n",
    "MMD_H0 = np.load(\"inverse_multiquadratic/data/COVID_real_world_analysis/MMD_H0_N1.npy\")\n",
    "draw_vline_to_kde(MMD_germany_standardized, kde, data_germany_color, label=r\"Germany data\")\n",
    "\n",
    "MMD_critical = np.quantile(MMD_H0, 1-alpha)\n",
    "#draw_vline_to_kde(MMD_critical, kde, alpha_color, linestyle=\"dashed\", label=r\"Critical value\")\n",
    "fill_area_under_kde(kde, MMD_critical, color=alpha_color, alpha=0.5, label=r\"5\\% rejection area\")\n",
    "\n",
    "sns.kdeplot(MMD_H0, fill=False, linewidth=3, color = H0_color, label=r\"$H_0$\", bw_adjust=bw_factor)\n",
    "\n",
    "\n",
    "plt.xlabel(r\"$\\widehat{\\mathrm{rMMD}}$\")\n",
    "plt.ylabel(\"\")\n",
    "plt.yticks([])\n",
    "plt.xlim(None, 3.95)\n",
    "\n",
    "plt.legend(fontsize=20)\n",
    "sns.despine()\n",
    "plt.savefig(f\"inverse_multiquadratic/plots/COVID_real_data_MMD_H0.{FILEFORMAT}\", bbox_inches=\"tight\", dpi=DPI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
