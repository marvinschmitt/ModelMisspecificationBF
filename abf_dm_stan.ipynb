{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "norman-precipitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import pickle\n",
    "from scipy import stats\n",
    "from functools import partial\n",
    "from numba import njit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "american-student",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "armed-given",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.gamma(2.5, 0.5, size=10000)\n",
    "sns.distplot(np.random.gamma(5, 0.5, size=10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-version",
   "metadata": {},
   "source": [
    "# Stan-friendly prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "altered-asthma",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def bounded_prior(batch_size):\n",
    "    \"\"\"\n",
    "    Samples from the prior 'batch_size' times.\n",
    "    ----------\n",
    "\n",
    "    Arguments:\n",
    "    batch_size : int -- the number of samples to draw from the prior\n",
    "    ----------\n",
    "\n",
    "    Output:\n",
    "    theta : np.ndarray of shape (batch_size, theta_dim) -- the samples batch of parameters\n",
    "    \"\"\"\n",
    "\n",
    "    # Prior ranges for the simulator\n",
    "    # v_c ~ U(0.1, 7.0)\n",
    "    # a_c ~ U(0.1, 4.0)\n",
    "    # t0 ~ U(0.1, 3.0)\n",
    "    \n",
    "    p_samples = np.random.uniform(low=(0.3, 0.3, 0.75, 0.5, 0.3),\n",
    "                                  high=(2.0, 2.0, 2.0, 2.0, 1.0), size=(batch_size, 5))\n",
    "    return p_samples.astype(np.float32)\n",
    "\n",
    "\n",
    "def unbounded_prior(batch_size):\n",
    "    \"\"\"\n",
    "    Samples from the prior 'batch_size' times.\n",
    "    ----------\n",
    "\n",
    "    Arguments:\n",
    "    batch_size : int -- the number of samples to draw from the prior\n",
    "    ----------\n",
    "\n",
    "    Output:\n",
    "    theta : np.ndarray of shape (batch_size, theta_dim) -- the samples batch of parameters\n",
    "    \"\"\"\n",
    "\n",
    "    # Prior ranges for the simulator\n",
    "    \n",
    "    p_samples = np.random.gamma(5, 0.5, size=(batch_size, 5))\n",
    "    return p_samples.astype(np.float32)\n",
    "\n",
    "\n",
    "@njit\n",
    "def diffusion_trial(v, a, ndt, zr, dt, max_steps):\n",
    "    \"\"\"Simulates a trial from the diffusion model.\"\"\"\n",
    "\n",
    "    n_steps = 0.\n",
    "    x = a * zr\n",
    "    rho = np.sqrt(dt)\n",
    "\n",
    "    # Simulate a single DM path\n",
    "    while (x > 0 and x < a and n_steps < max_steps):\n",
    "\n",
    "        # DDM equation\n",
    "        x += v*dt +  rho * np.random.normal()\n",
    "\n",
    "        # Increment step\n",
    "        n_steps += 1.0\n",
    "\n",
    "    rt = n_steps * dt\n",
    "    return rt + ndt if x > 0. else -rt - ndt\n",
    "\n",
    "@njit\n",
    "def diffusion_condition(n_trials, v, a, ndt, zr=0.5, dt=0.005, max_steps=1e4):\n",
    "    \"\"\"Simulates a diffusion process over an entire condition.\"\"\"\n",
    "\n",
    "    x = np.empty(n_trials)\n",
    "    for i in range(n_trials):\n",
    "        x[i] = diffusion_trial(v, a, ndt, zr, dt, max_steps)\n",
    "    return x\n",
    "\n",
    "\n",
    "@njit\n",
    "def diffusion_2_conds(params, n_trials, dt=0.001, max_steps=1e4):\n",
    "    \"\"\"\n",
    "    Simulates a diffusion process for 2 conditions with 5 parameters (v1, v2, a1, a2, ndt).\n",
    "    \"\"\"\n",
    "\n",
    "    n_trials_c1 = n_trials[0]\n",
    "    n_trials_c2 = n_trials[1]\n",
    "\n",
    "    v1, v2, a1, a2, ndt = params\n",
    "    rt_c1 = diffusion_condition(n_trials_c1, v1, a1, ndt,  dt=dt, max_steps=max_steps)\n",
    "    rt_c2 = diffusion_condition(n_trials_c2, v2, a2, ndt, dt=dt, max_steps=max_steps)\n",
    "    rts = np.concatenate((rt_c1, rt_c2))\n",
    "    return rts\n",
    "\n",
    "\n",
    "def batch_simulator(prior_samples, n_obs, dt=0.001, s=1.0, max_iter=1e4):\n",
    "    \"\"\"\n",
    "    Simulate multiple diffusion_model_datasets.\n",
    "    \"\"\"\n",
    "\n",
    "    n_sim = prior_samples.shape[0]\n",
    "    sim_data = np.empty((n_sim, n_obs), dtype=np.float32)\n",
    "\n",
    "    n1 = n_obs//2\n",
    "    n2 = n_obs - n1\n",
    "\n",
    "    # Simulate diffusion data \n",
    "    for i in range(n_sim):\n",
    "        sim_data[i] = diffusion_2_conds(prior_samples[i], (n1, n2))\n",
    "\n",
    "    # Create condition labels\n",
    "    cond_arr = np.stack(n_sim * [np.concatenate((np.zeros(n1), np.ones(n2)))] )\n",
    "    sim_data = np.stack((sim_data, cond_arr), axis=-1)\n",
    "\n",
    "    return sim_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ongoing-witch",
   "metadata": {},
   "source": [
    "# Stan Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "outdoor-collect",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "stan_model = \"\"\"\n",
    "data {\n",
    "  int<lower=0> N;                    \n",
    "  real<lower=0> x1[N];   \n",
    "  real<lower=0> x2[N];   \n",
    "  int<lower=0,upper=1> resp1[N];  \n",
    "  int<lower=0,upper=1> resp2[N];  \n",
    "}\n",
    "\n",
    "parameters {\n",
    "  real<lower=0> drift1;\n",
    "  real<lower=0> drift2;\n",
    "  real<lower=0> bs1; \n",
    "  real<lower=0> bs2; \n",
    "  real<lower=0> ndt;\n",
    "}\n",
    "\n",
    "model {\n",
    "  // Ndt-prior min-max\n",
    "\n",
    "  // Priors\n",
    "  drift1 ~ gamma(5, 0.5);\n",
    "  drift2 ~ gamma(5, 0.5);\n",
    "  bs1 ~ gamma(5, 0.5);\n",
    "  bs2 ~ gamma(5, 0.5);\n",
    "  ndt ~ gamma(5, 0.5);\n",
    "  \n",
    "  // First condition\n",
    "  for (n in 1:N) {\n",
    "     if (resp1[n] == 1) {\n",
    "        x1[n] ~ wiener(bs1, ndt, 0.5, drift1);\n",
    "     } \n",
    "     else {\n",
    "        x1[n] ~ wiener(bs1, ndt, 1 - 0.5, -drift1);\n",
    "     }\n",
    "  }\n",
    "  \n",
    "  // Second condition\n",
    "  for (n in 1:N) {\n",
    "     if (resp2[n] == 1) {\n",
    "        x2[n] ~ wiener(bs2, ndt, 0.5, drift2);\n",
    "     } \n",
    "     else {\n",
    "        x2[n] ~ wiener(bs2, ndt, 1 - 0.5, -drift2);\n",
    "     }\n",
    "  }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thick-adams",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "legal-engineering",
   "metadata": {
    "code_folding": [
     10,
     18,
     21,
     24,
     31,
     54,
     62
    ]
   },
   "outputs": [],
   "source": [
    "# Format for stan\n",
    "def to_stan(sim_data):\n",
    "    x1 = sim_data[sim_data[:, 1] == 0, 0]\n",
    "    x2 = sim_data[sim_data[:, 1] == 1, 0]\n",
    "    resp1 = (x1 >= 0).astype(np.int64)\n",
    "    resp2 = (x2 >= 0).astype(np.int64)\n",
    "    x1 = np.abs(x1).astype(np.float64)\n",
    "    x2 = np.abs(x2).astype(np.float64)\n",
    "    return {'x1': x1, 'x2': x2, 'resp1': resp1, 'resp2': resp2, 'N': x1.shape[0]}\n",
    "\n",
    "def params_to_dict(params):\n",
    "    \n",
    "    return {'drift1': params[0],\n",
    "            'drift2': params[1],\n",
    "            'bs1': params[2],\n",
    "            'bs2': params[3],\n",
    "            'ndt': params[4]}\n",
    "\n",
    "def contamination_dist_fast_guesses(percentiles, n):    \n",
    "    return np.random.uniform(0.1, percentiles[10], n)\n",
    "\n",
    "def contamination_dist_slow_responses(percentiles, n):\n",
    "    return np.random.uniform(percentiles[75], 10.0, n)\n",
    "\n",
    "def contamination_dist_fast_and_slow(percentiles, n):\n",
    "    n1 = int(n/2)\n",
    "    n2 = n-n1\n",
    "    fast = contamination_dist_fast_guesses(percentiles, n1)\n",
    "    slow = contamination_dist_slow_responses(percentiles, n2)\n",
    "    return np.concatenate((fast, slow))\n",
    "\n",
    "def contaminate(x, contamination_dist, c=0.1):\n",
    "    \"\"\"\n",
    "    Contaminate the random variate vector x with contaminants according to fraction c \\in [0, 1]\n",
    "    \"\"\"\n",
    "    #x_contamination = x.copy()\n",
    "    \n",
    "    if not x.size > 0:\n",
    "        return x\n",
    "\n",
    "    \n",
    "    n = x.shape[0]\n",
    "    n_contamination = int(n * c)\n",
    "    contamination_idx = np.random.default_rng().choice(n, size=n_contamination, replace=False)\n",
    "    \n",
    "    percentiles = np.percentile(x, range(101))\n",
    "    \n",
    "    sampled_contamination = contamination_dist(percentiles, n_contamination)\n",
    "    assert sampled_contamination.shape[0] == n_contamination\n",
    "    \n",
    "    \n",
    "    x[contamination_idx] = sampled_contamination\n",
    "    return x\n",
    "\n",
    "def split_posneg_contaminate(x, contamination_dist, c):\n",
    "    pos_idx = np.where(x>=0)\n",
    "    neg_idx = np.where(x<0)\n",
    "    \n",
    "    x[pos_idx] = contaminate(x[pos_idx], contamination_dist=contamination_dist, c=c)\n",
    "    x[neg_idx] = contaminate(x[neg_idx], contamination_dist=contamination_dist, c=c)\n",
    "    return x\n",
    "\n",
    "def contaminate_dm_data(x, contamination_dist, c=0.1):\n",
    "    x_copy = x.copy()\n",
    "    n_sim, n_obs, data_dim = x_copy.shape\n",
    "    for bi in range(n_sim):\n",
    "        x_copy[bi, :(n_obs//2), 0] = split_posneg_contaminate(x_copy[bi, :(n_obs//2), 0], contamination_dist, c=c)\n",
    "        x_copy[bi, (n_obs//2):, 0] = split_posneg_contaminate(x_copy[bi, (n_obs//2):, 0], contamination_dist, c=c)\n",
    "    return x_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-layout",
   "metadata": {},
   "source": [
    "# Simulate and contaminate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "inclusive-ministry",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2021)\n",
    "params = unbounded_prior(100)\n",
    "data_clean = batch_simulator(params, n_obs=100)\n",
    "data_slow = contaminate_dm_data(data_clean, contamination_dist=contamination_dist_slow_responses, c=0.1)\n",
    "data_fast = contaminate_dm_data(data_clean, contamination_dist=contamination_dist_fast_guesses, c=0.1)\n",
    "data_fast_slow = contaminate_dm_data(data_clean, contamination_dist=contamination_dist_fast_and_slow, c=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loving-orientation",
   "metadata": {},
   "source": [
    "# Compile stan model and perform inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "trying-increase",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_08d85dd2ea054476fe2ff1d91f0b0ec9 NOW.\n"
     ]
    }
   ],
   "source": [
    "sm = pystan.StanModel(model_code=stan_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "addressed-theater",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # data_i = to_stan(data_slow[0])\n",
    "# data_i = to_stan(data_clean[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "committed-start",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ndt_init = min(data_i['x2'].min(), data_i['x1'].min()) * .75\n",
    "# init = {'ndt': ndt_init}\n",
    "# fit = sm.sampling(data=data_i, iter=2000, chains=4, \n",
    "#                   n_jobs=4, control=dict(adapt_delta=0.99, max_treedepth=15), init=[init, init, init, init])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designing-syndicate",
   "metadata": {},
   "source": [
    "## Estimate posterior for slow contamination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "patient-falls",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished estimating data set 1...\n",
      "Finished estimating data set 2...\n",
      "Finished estimating data set 3...\n",
      "Finished estimating data set 4...\n",
      "Finished estimating data set 5...\n",
      "Finished estimating data set 6...\n",
      "Finished estimating data set 7...\n",
      "Finished estimating data set 8...\n",
      "Finished estimating data set 9...\n",
      "Finished estimating data set 10...\n",
      "Finished estimating data set 11...\n",
      "Finished estimating data set 12...\n",
      "Finished estimating data set 13...\n",
      "Finished estimating data set 14...\n",
      "Finished estimating data set 15...\n",
      "Finished estimating data set 16...\n",
      "Finished estimating data set 17...\n",
      "Finished estimating data set 18...\n",
      "Finished estimating data set 19...\n",
      "Finished estimating data set 20...\n",
      "Finished estimating data set 21...\n",
      "Finished estimating data set 22...\n",
      "Finished estimating data set 23...\n",
      "Finished estimating data set 24...\n",
      "Finished estimating data set 25...\n",
      "Finished estimating data set 26...\n",
      "Finished estimating data set 27...\n",
      "Finished estimating data set 28...\n",
      "Finished estimating data set 29...\n",
      "Finished estimating data set 30...\n",
      "Finished estimating data set 31...\n",
      "Finished estimating data set 32...\n",
      "Finished estimating data set 33...\n",
      "Finished estimating data set 34...\n",
      "Finished estimating data set 35...\n",
      "Finished estimating data set 36...\n",
      "Finished estimating data set 37...\n",
      "Finished estimating data set 38...\n",
      "Finished estimating data set 39...\n",
      "Finished estimating data set 40...\n",
      "Finished estimating data set 41...\n",
      "Finished estimating data set 42...\n",
      "Finished estimating data set 43...\n",
      "Finished estimating data set 44...\n",
      "Finished estimating data set 45...\n",
      "Finished estimating data set 46...\n",
      "Finished estimating data set 47...\n",
      "Finished estimating data set 48...\n",
      "Finished estimating data set 49...\n",
      "Finished estimating data set 50...\n",
      "Finished estimating data set 51...\n",
      "Finished estimating data set 52...\n",
      "Finished estimating data set 53...\n",
      "Finished estimating data set 54...\n",
      "Finished estimating data set 55...\n",
      "Finished estimating data set 56...\n",
      "Finished estimating data set 57...\n",
      "Finished estimating data set 58...\n",
      "Finished estimating data set 59...\n",
      "Finished estimating data set 60...\n",
      "Finished estimating data set 61...\n",
      "Finished estimating data set 62...\n",
      "Finished estimating data set 63...\n",
      "Finished estimating data set 64...\n",
      "Finished estimating data set 65...\n",
      "Finished estimating data set 66...\n",
      "Finished estimating data set 67...\n",
      "Finished estimating data set 68...\n",
      "Finished estimating data set 69...\n",
      "Finished estimating data set 70...\n",
      "Finished estimating data set 71...\n",
      "Finished estimating data set 72...\n",
      "Finished estimating data set 73...\n",
      "Finished estimating data set 74...\n",
      "Finished estimating data set 75...\n",
      "Finished estimating data set 76...\n",
      "Finished estimating data set 77...\n",
      "Finished estimating data set 78...\n",
      "Finished estimating data set 79...\n",
      "Finished estimating data set 80...\n",
      "Finished estimating data set 81...\n",
      "Finished estimating data set 82...\n",
      "Finished estimating data set 83...\n",
      "Finished estimating data set 84...\n",
      "Finished estimating data set 85...\n",
      "Finished estimating data set 86...\n",
      "Finished estimating data set 87...\n",
      "Finished estimating data set 88...\n",
      "Finished estimating data set 89...\n",
      "Finished estimating data set 90...\n",
      "Finished estimating data set 91...\n",
      "Finished estimating data set 92...\n",
      "Finished estimating data set 93...\n",
      "Finished estimating data set 94...\n",
      "Finished estimating data set 95...\n",
      "Finished estimating data set 96...\n",
      "Finished estimating data set 97...\n",
      "Finished estimating data set 98...\n",
      "Finished estimating data set 99...\n",
      "Finished estimating data set 100...\n",
      "Wall time: 27min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stan_post_samples_slow = []\n",
    "for idx in range(data_clean.shape[0]):\n",
    "    data_i = to_stan(data_slow[idx])\n",
    "    ndt_init = min(data_i['x2'].min(), data_i['x1'].min()) * .75\n",
    "    init = {'ndt': ndt_init}\n",
    "    fit = sm.sampling(data=data_i, \n",
    "                      iter=2000, chains=4, n_jobs=4, init=[init, init, init, init],\n",
    "                      control=dict(adapt_delta=0.99, max_treedepth=15))\n",
    "    samples = fit.extract(permuted=True)\n",
    "    stan_post_samples_slow.append(samples)\n",
    "    print(f'Finished estimating data set {idx+1}...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-mississippi",
   "metadata": {},
   "source": [
    "## Estimate posterior for fast contamination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "measured-singles",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished estimating data set 1...\n",
      "Finished estimating data set 2...\n",
      "Finished estimating data set 3...\n",
      "Finished estimating data set 4...\n",
      "Finished estimating data set 5...\n",
      "Finished estimating data set 6...\n",
      "Finished estimating data set 7...\n",
      "Finished estimating data set 8...\n",
      "Finished estimating data set 9...\n",
      "Finished estimating data set 10...\n",
      "Finished estimating data set 11...\n",
      "Finished estimating data set 12...\n",
      "Finished estimating data set 13...\n",
      "Finished estimating data set 14...\n",
      "Finished estimating data set 15...\n",
      "Finished estimating data set 16...\n",
      "Finished estimating data set 17...\n",
      "Finished estimating data set 18...\n",
      "Finished estimating data set 19...\n",
      "Finished estimating data set 20...\n",
      "Finished estimating data set 21...\n",
      "Finished estimating data set 22...\n",
      "Finished estimating data set 23...\n",
      "Finished estimating data set 24...\n",
      "Finished estimating data set 25...\n",
      "Finished estimating data set 26...\n",
      "Finished estimating data set 27...\n",
      "Finished estimating data set 28...\n",
      "Finished estimating data set 29...\n",
      "Finished estimating data set 30...\n",
      "Finished estimating data set 31...\n",
      "Finished estimating data set 32...\n",
      "Finished estimating data set 33...\n",
      "Finished estimating data set 34...\n",
      "Finished estimating data set 35...\n",
      "Finished estimating data set 36...\n",
      "Finished estimating data set 37...\n",
      "Finished estimating data set 38...\n",
      "Finished estimating data set 39...\n",
      "Finished estimating data set 40...\n",
      "Finished estimating data set 41...\n",
      "Finished estimating data set 42...\n",
      "Finished estimating data set 43...\n",
      "Finished estimating data set 44...\n",
      "Finished estimating data set 45...\n",
      "Finished estimating data set 46...\n",
      "Finished estimating data set 47...\n",
      "Finished estimating data set 48...\n",
      "Finished estimating data set 49...\n",
      "Finished estimating data set 50...\n",
      "Finished estimating data set 51...\n",
      "Finished estimating data set 52...\n",
      "Finished estimating data set 53...\n",
      "Finished estimating data set 54...\n",
      "Finished estimating data set 55...\n",
      "Finished estimating data set 56...\n",
      "Finished estimating data set 57...\n",
      "Finished estimating data set 58...\n",
      "Finished estimating data set 59...\n",
      "Finished estimating data set 60...\n",
      "Finished estimating data set 61...\n",
      "Finished estimating data set 62...\n",
      "Finished estimating data set 63...\n",
      "Finished estimating data set 64...\n",
      "Finished estimating data set 65...\n",
      "Finished estimating data set 66...\n",
      "Finished estimating data set 67...\n",
      "Finished estimating data set 68...\n",
      "Finished estimating data set 69...\n",
      "Finished estimating data set 70...\n",
      "Finished estimating data set 71...\n",
      "Finished estimating data set 72...\n",
      "Finished estimating data set 73...\n",
      "Finished estimating data set 74...\n",
      "Finished estimating data set 75...\n",
      "Finished estimating data set 76...\n",
      "Finished estimating data set 77...\n",
      "Finished estimating data set 78...\n",
      "Finished estimating data set 79...\n",
      "Finished estimating data set 80...\n",
      "Finished estimating data set 81...\n",
      "Finished estimating data set 82...\n",
      "Finished estimating data set 83...\n",
      "Finished estimating data set 84...\n",
      "Finished estimating data set 85...\n",
      "Finished estimating data set 86...\n",
      "Finished estimating data set 87...\n",
      "Finished estimating data set 88...\n",
      "Finished estimating data set 89...\n",
      "Finished estimating data set 90...\n",
      "Finished estimating data set 91...\n",
      "Finished estimating data set 92...\n",
      "Finished estimating data set 93...\n",
      "Finished estimating data set 94...\n",
      "Finished estimating data set 95...\n",
      "Finished estimating data set 96...\n",
      "Finished estimating data set 97...\n",
      "Finished estimating data set 98...\n",
      "Finished estimating data set 99...\n",
      "Finished estimating data set 100...\n"
     ]
    }
   ],
   "source": [
    "stan_post_samples_fast = []\n",
    "for idx in range(data_clean.shape[0]):\n",
    "    data_i = to_stan(data_fast[idx])\n",
    "    ndt_init = min(data_i['x2'].min(), data_i['x1'].min()) * .75\n",
    "    init = {'ndt': ndt_init}\n",
    "    fit = sm.sampling(data=data_i, \n",
    "                      iter=2000, chains=4, n_jobs=4, init=[init, init, init, init],\n",
    "                      control=dict(adapt_delta=0.99, max_treedepth=15))\n",
    "    samples = fit.extract(permuted=True)\n",
    "    stan_post_samples_fast.append(samples)\n",
    "    print(f'Finished estimating data set {idx+1}...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-chile",
   "metadata": {},
   "source": [
    "## Estimate posteriors for slow and fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "polyphonic-spain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished estimating data set 1...\n",
      "Finished estimating data set 2...\n",
      "Finished estimating data set 3...\n",
      "Finished estimating data set 4...\n",
      "Finished estimating data set 5...\n",
      "Finished estimating data set 6...\n",
      "Finished estimating data set 7...\n",
      "Finished estimating data set 8...\n",
      "Finished estimating data set 9...\n",
      "Finished estimating data set 10...\n",
      "Finished estimating data set 11...\n",
      "Finished estimating data set 12...\n",
      "Finished estimating data set 13...\n",
      "Finished estimating data set 14...\n",
      "Finished estimating data set 15...\n",
      "Finished estimating data set 16...\n",
      "Finished estimating data set 17...\n",
      "Finished estimating data set 18...\n",
      "Finished estimating data set 19...\n",
      "Finished estimating data set 20...\n",
      "Finished estimating data set 21...\n",
      "Finished estimating data set 22...\n",
      "Finished estimating data set 23...\n",
      "Finished estimating data set 24...\n",
      "Finished estimating data set 25...\n",
      "Finished estimating data set 26...\n",
      "Finished estimating data set 27...\n",
      "Finished estimating data set 28...\n",
      "Finished estimating data set 29...\n",
      "Finished estimating data set 30...\n",
      "Finished estimating data set 31...\n",
      "Finished estimating data set 32...\n",
      "Finished estimating data set 33...\n",
      "Finished estimating data set 34...\n",
      "Finished estimating data set 35...\n",
      "Finished estimating data set 36...\n",
      "Finished estimating data set 37...\n",
      "Finished estimating data set 38...\n",
      "Finished estimating data set 39...\n",
      "Finished estimating data set 40...\n",
      "Finished estimating data set 41...\n",
      "Finished estimating data set 42...\n",
      "Finished estimating data set 43...\n",
      "Finished estimating data set 44...\n",
      "Finished estimating data set 45...\n",
      "Finished estimating data set 46...\n",
      "Finished estimating data set 47...\n",
      "Finished estimating data set 48...\n",
      "Finished estimating data set 49...\n",
      "Finished estimating data set 50...\n",
      "Finished estimating data set 51...\n",
      "Finished estimating data set 52...\n",
      "Finished estimating data set 53...\n",
      "Finished estimating data set 54...\n",
      "Finished estimating data set 55...\n",
      "Finished estimating data set 56...\n",
      "Finished estimating data set 57...\n",
      "Finished estimating data set 58...\n",
      "Finished estimating data set 59...\n",
      "Finished estimating data set 60...\n",
      "Finished estimating data set 61...\n",
      "Finished estimating data set 62...\n",
      "Finished estimating data set 63...\n",
      "Finished estimating data set 64...\n",
      "Finished estimating data set 65...\n",
      "Finished estimating data set 66...\n",
      "Finished estimating data set 67...\n",
      "Finished estimating data set 68...\n",
      "Finished estimating data set 69...\n",
      "Finished estimating data set 70...\n",
      "Finished estimating data set 71...\n",
      "Finished estimating data set 72...\n",
      "Finished estimating data set 73...\n",
      "Finished estimating data set 74...\n",
      "Finished estimating data set 75...\n",
      "Finished estimating data set 76...\n",
      "Finished estimating data set 77...\n",
      "Finished estimating data set 78...\n",
      "Finished estimating data set 79...\n",
      "Finished estimating data set 80...\n",
      "Finished estimating data set 81...\n",
      "Finished estimating data set 82...\n",
      "Finished estimating data set 83...\n",
      "Finished estimating data set 84...\n",
      "Finished estimating data set 85...\n",
      "Finished estimating data set 86...\n",
      "Finished estimating data set 87...\n",
      "Finished estimating data set 88...\n",
      "Finished estimating data set 89...\n",
      "Finished estimating data set 90...\n",
      "Finished estimating data set 91...\n",
      "Finished estimating data set 92...\n",
      "Finished estimating data set 93...\n",
      "Finished estimating data set 94...\n",
      "Finished estimating data set 95...\n",
      "Finished estimating data set 96...\n",
      "Finished estimating data set 97...\n",
      "Finished estimating data set 98...\n",
      "Finished estimating data set 99...\n",
      "Finished estimating data set 100...\n"
     ]
    }
   ],
   "source": [
    "stan_post_samples_fast_slow = []\n",
    "for idx in range(data_clean.shape[0]):\n",
    "    data_i = to_stan(data_fast_slow[idx])\n",
    "    ndt_init = min(data_i['x2'].min(), data_i['x1'].min()) * .75\n",
    "    init = {'ndt': ndt_init}\n",
    "    fit = sm.sampling(data=data_i, \n",
    "                      iter=2000, chains=4, n_jobs=4, init=[init, init, init, init],\n",
    "                      control=dict(adapt_delta=0.99, max_treedepth=15))\n",
    "    samples = fit.extract(permuted=True)\n",
    "    stan_post_samples_fast_slow.append(samples)\n",
    "    print(f'Finished estimating data set {idx+1}...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intellectual-favorite",
   "metadata": {},
   "source": [
    "## Estimate posteriors for clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "needed-nursery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished estimating data set 1...\n",
      "Finished estimating data set 2...\n",
      "Finished estimating data set 3...\n",
      "Finished estimating data set 4...\n",
      "Finished estimating data set 5...\n",
      "Finished estimating data set 6...\n",
      "Finished estimating data set 7...\n",
      "Finished estimating data set 8...\n",
      "Finished estimating data set 9...\n",
      "Finished estimating data set 10...\n",
      "Finished estimating data set 11...\n",
      "Finished estimating data set 12...\n",
      "Finished estimating data set 13...\n",
      "Finished estimating data set 14...\n",
      "Finished estimating data set 15...\n",
      "Finished estimating data set 16...\n",
      "Finished estimating data set 17...\n",
      "Finished estimating data set 18...\n",
      "Finished estimating data set 19...\n",
      "Finished estimating data set 20...\n",
      "Finished estimating data set 21...\n",
      "Finished estimating data set 22...\n",
      "Finished estimating data set 23...\n",
      "Finished estimating data set 24...\n",
      "Finished estimating data set 25...\n",
      "Finished estimating data set 26...\n",
      "Finished estimating data set 27...\n",
      "Finished estimating data set 28...\n",
      "Finished estimating data set 29...\n",
      "Finished estimating data set 30...\n",
      "Finished estimating data set 31...\n",
      "Finished estimating data set 32...\n",
      "Finished estimating data set 33...\n",
      "Finished estimating data set 34...\n",
      "Finished estimating data set 35...\n",
      "Finished estimating data set 36...\n",
      "Finished estimating data set 37...\n",
      "Finished estimating data set 38...\n",
      "Finished estimating data set 39...\n",
      "Finished estimating data set 40...\n",
      "Finished estimating data set 41...\n",
      "Finished estimating data set 42...\n",
      "Finished estimating data set 43...\n",
      "Finished estimating data set 44...\n",
      "Finished estimating data set 45...\n",
      "Finished estimating data set 46...\n",
      "Finished estimating data set 47...\n",
      "Finished estimating data set 48...\n",
      "Finished estimating data set 49...\n",
      "Finished estimating data set 50...\n",
      "Finished estimating data set 51...\n",
      "Finished estimating data set 52...\n",
      "Finished estimating data set 53...\n",
      "Finished estimating data set 54...\n",
      "Finished estimating data set 55...\n",
      "Finished estimating data set 56...\n",
      "Finished estimating data set 57...\n",
      "Finished estimating data set 58...\n",
      "Finished estimating data set 59...\n",
      "Finished estimating data set 60...\n",
      "Finished estimating data set 61...\n",
      "Finished estimating data set 62...\n",
      "Finished estimating data set 63...\n",
      "Finished estimating data set 64...\n",
      "Finished estimating data set 65...\n",
      "Finished estimating data set 66...\n",
      "Finished estimating data set 67...\n",
      "Finished estimating data set 68...\n",
      "Finished estimating data set 69...\n",
      "Finished estimating data set 70...\n",
      "Finished estimating data set 71...\n",
      "Finished estimating data set 72...\n",
      "Finished estimating data set 73...\n",
      "Finished estimating data set 74...\n",
      "Finished estimating data set 75...\n",
      "Finished estimating data set 76...\n",
      "Finished estimating data set 77...\n",
      "Finished estimating data set 78...\n",
      "Finished estimating data set 79...\n",
      "Finished estimating data set 80...\n",
      "Finished estimating data set 81...\n",
      "Finished estimating data set 82...\n",
      "Finished estimating data set 83...\n",
      "Finished estimating data set 84...\n",
      "Finished estimating data set 85...\n",
      "Finished estimating data set 86...\n",
      "Finished estimating data set 87...\n",
      "Finished estimating data set 88...\n",
      "Finished estimating data set 89...\n",
      "Finished estimating data set 90...\n",
      "Finished estimating data set 91...\n",
      "Finished estimating data set 92...\n",
      "Finished estimating data set 93...\n",
      "Finished estimating data set 94...\n",
      "Finished estimating data set 95...\n",
      "Finished estimating data set 96...\n",
      "Finished estimating data set 97...\n",
      "Finished estimating data set 98...\n",
      "Finished estimating data set 99...\n",
      "Finished estimating data set 100...\n"
     ]
    }
   ],
   "source": [
    "stan_post_samples_clean = []\n",
    "for idx in range(data_clean.shape[0]):\n",
    "    data_i = to_stan(data_clean[idx])\n",
    "    ndt_init = min(data_i['x2'].min(), data_i['x1'].min()) * .75\n",
    "    init = {'ndt': ndt_init}\n",
    "    fit = sm.sampling(data=data_i, \n",
    "                      iter=2000, chains=4, n_jobs=4, init=[init, init, init, init],\n",
    "                      control=dict(adapt_delta=0.99, max_treedepth=15))\n",
    "    samples = fit.extract(permuted=True)\n",
    "    stan_post_samples_clean.append(samples)\n",
    "    print(f'Finished estimating data set {idx+1}...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxed-cholesterol",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove posteriors of data set idx 91 due to a high percentage of divergences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "union-algorithm",
   "metadata": {},
   "source": [
    "## Serialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "informal-colors",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(\n",
    "{\n",
    "    'clean': stan_post_samples_clean, \n",
    "    'slow': stan_post_samples_slow, \n",
    "    'fast': stan_post_samples_fast, \n",
    "    'fast_slow': stan_post_samples_fast_slow, \n",
    "    }, \n",
    "    open('./export_stan_posteriors/stan_posteriors.pkl', 'wb+')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "secret-diagnosis",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(\n",
    "{\n",
    "    'clean': data_clean, \n",
    "    'slow': data_slow,\n",
    "    'fast': data_fast,\n",
    "    'fast_slow': data_fast_slow\n",
    "    }, \n",
    "    open('./export_stan_posteriors/data_posteriors.pkl', 'wb+')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "forbidden-judge",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(\n",
    "    params,\n",
    "    open('./export_stan_posteriors/params.pkl', 'wb+')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-alexandria",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
