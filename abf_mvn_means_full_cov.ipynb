{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Adversarial BayesFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2: MVN means and full covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from scipy import stats\n",
    "from functools import partial\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('../BayesFlow')))\n",
    "\n",
    "from bayesflow.trainers import ParameterEstimationTrainer\n",
    "from bayesflow.networks import InvertibleNetwork, InvariantNetwork\n",
    "from bayesflow.amortizers import SingleModelAmortizer\n",
    "from bayesflow.models import GenerativeModel\n",
    "from bayesflow.exceptions import ConfigurationError\n",
    "from bayesflow.applications.priors import GaussianMeanPrior, TPrior, GaussianMeanCovPrior\n",
    "from bayesflow.applications.simulators import GaussianMeanSimulator, MultivariateTSimulator, GaussianMeanCovSimulator\n",
    "\n",
    "from abf_functions import *\n",
    "\n",
    "RERUN_GRID_EXPERIMENT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    \"axes.labelsize\" : 20,\n",
    "    \"xtick.labelsize\" : 16,\n",
    "    \"ytick.labelsize\" : 16,\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Times\"],\n",
    "    'text.latex.preamble' : r'\\usepackage{{amsmath}}'\n",
    "})\n",
    "\n",
    "FILEFORMAT = 'pdf'\n",
    "DPI = 300\n",
    "\n",
    "color_codes = {\n",
    "\n",
    "    \"Prior location\" : \"goldenrod\",\n",
    "    \"Prior scale\" : \"firebrick\",\n",
    "    \"Prior location + scale\" : \"darkgreen\",\n",
    "    \"Simulator\" : \"yellowgreen\",\n",
    "    \"Noise\" : \"mediumvioletred\",\n",
    "    \"No MMS\" : \"royalblue\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices: tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 5\n",
    "\n",
    "#########\n",
    "\n",
    "class NormalInverseWishartPrior:\n",
    "    def __init__(self, D, mu_0=0.0, lamda_0=1.0, Psi_0=None, nu_0=None):\n",
    "        if Psi_0 is None:\n",
    "            Psi_0 = np.eye(D)\n",
    "        if nu_0 is None:\n",
    "            nu_0 = D+1\n",
    "        self.D = D,\n",
    "        self.mu_0 = mu_0\n",
    "        self.lamda_0 = lamda_0\n",
    "        self.Psi_0 = Psi_0\n",
    "        self.nu_0 = nu_0\n",
    "        \n",
    "        self.cov_prior = stats.invwishart(self.nu_0, self.Psi_0)\n",
    "        \n",
    "    def __call__(self, n_sim):\n",
    "        cov = self.cov_prior.rvs(n_sim)\n",
    "        tril_cov = tf.linalg.cholesky((1.0 / self.lamda_0) * cov)\n",
    "        means = tfp.distributions.MultivariateNormalTriL(self.mu_0, tril_cov).sample()\n",
    "        \n",
    "        return np.array(means, dtype=np.float32), np.array(cov, dtype=np.float32)\n",
    "\n",
    "\n",
    "def param_transform_full_cov(theta):\n",
    "    means, cov = theta\n",
    "    means = np.array(means)\n",
    "    n_sim, D = means.shape\n",
    "    cov = np.array(cov)\n",
    "    cov = cov[np.tril(cov).nonzero()].reshape(n_sim, -1)\n",
    "    return np.concatenate([means, cov], axis=1)\n",
    "\n",
    "\n",
    "mu_0 = 0.0\n",
    "lamda_0 = 5\n",
    "Psi_0 = np.eye(D)\n",
    "nu_0 = 10\n",
    "prior = NormalInverseWishartPrior(D=D, mu_0=mu_0, lamda_0=lamda_0, Psi_0=Psi_0, nu_0=nu_0)\n",
    "simulator = GaussianMeanCovSimulator()\n",
    "generative_model = GenerativeModel(prior, simulator, param_transform=param_transform_full_cov)\n",
    "\n",
    "#########\n",
    "\n",
    "summary_meta = {\n",
    "    'n_dense_s1': 2,\n",
    "    'n_dense_s2': 2,\n",
    "    'n_dense_s3': 2,\n",
    "    'n_equiv':    2,\n",
    "    'dense_s1_args': {'activation': 'relu', 'units': 64},\n",
    "    'dense_s2_args': {'activation': 'relu', 'units': 64},\n",
    "    'dense_s3_args': {'activation': 'relu', 'units': 64},\n",
    "}\n",
    "\n",
    "class BottleneckSummaryNet(tf.keras.Model):\n",
    "    def __init__(self, inv_meta={}, n_out=10, activation_out=None):\n",
    "        super(BottleneckSummaryNet, self).__init__()\n",
    "\n",
    "        self.invariant_net = InvariantNetwork(inv_meta)\n",
    "        self.out_layer = tf.keras.layers.Dense(n_out, activation=activation_out)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        out_inv = self.invariant_net(x)\n",
    "        out = self.out_layer(out_inv)\n",
    "        return out\n",
    "\n",
    "\n",
    "summary_net = BottleneckSummaryNet(inv_meta=summary_meta, \n",
    "                                   n_out=(sum(range(1, D+1)) + D),  \n",
    "                                   activation_out=None  # linear\n",
    ")\n",
    "\n",
    "\n",
    "inference_meta = {\n",
    "    'n_coupling_layers': 4,\n",
    "    's_args': {\n",
    "        'units': [128, 128],\n",
    "        'activation': 'elu',\n",
    "        'initializer': 'glorot_uniform',\n",
    "    },\n",
    "    't_args': {\n",
    "        'units': [128, 128],\n",
    "        'activation': 'elu',\n",
    "        'initializer': 'glorot_uniform',\n",
    "    },\n",
    "    'n_params': sum(range(1, D+1)) + D,   # lower diagonal cov (1+2+...+D) and D means\n",
    "    'alpha': 1.9,\n",
    "    'permute': True\n",
    "}\n",
    "\n",
    "inference_net = InvertibleNetwork(inference_meta)\n",
    "\n",
    "amortizer = SingleModelAmortizer(inference_net, summary_net)\n",
    "\n",
    "trainer = ParameterEstimationTrainer(amortizer,\n",
    "                      generative_model,\n",
    "                      loss=mmd_kl_loss,\n",
    "                      learning_rate=0.0005,\n",
    "                      checkpoint_path='export_ckpt/mmd/full_cov_5D',\n",
    "                      max_to_keep = 2\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses = trainer.train_rounds(epochs=10, rounds=10, sim_per_round=10000, batch_size=128, n_obs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_list_to_mean_cov(theta, D):\n",
    "    # setup\n",
    "    n_sim = theta.shape[0]\n",
    "    mean = theta[:, :D]\n",
    "    cov_list = theta[:, D:]\n",
    "    tril_idx1, tril_idx2 = np.tril_indices(D)\n",
    "    cov = np.zeros((n_sim, D, D))\n",
    "    \n",
    "    # fill cov matrix\n",
    "    for i in range(n_sim):\n",
    "        # write from flattened array into in lower triangular matrix\n",
    "        cov[i, tril_idx1, tril_idx2] = cov_list[i, :]\n",
    "        \n",
    "        # mirror lower triangular matrix to upper triangle\n",
    "        cov[i] = cov[i] + cov[i].T - np.diag(np.diag(cov[i]))\n",
    "    return mean, cov\n",
    "\n",
    "def cov_to_corr(cov, std_devs_on_diagonal=True, epsilon=1e-6):\n",
    "    corr = np.zeros_like(cov)\n",
    "    n_sim = cov.shape[0]\n",
    "    \n",
    "    for i in range(n_sim):\n",
    "        # extract 2D matrix\n",
    "        Sigma = cov[i, :, :]\n",
    "        \n",
    "        # transform 2D cov matrix into corr matrix\n",
    "        std_devs = np.sqrt(np.maximum(np.diag(Sigma), epsilon))\n",
    "        Dinv = np.diag(1 / std_devs)\n",
    "        corr[i] = Dinv @ Sigma @ Dinv\n",
    "        \n",
    "        # increase information by putting SDs on diagonal instead of 1's\n",
    "        if std_devs_on_diagonal:\n",
    "            np.fill_diagonal(corr[i], std_devs)\n",
    "            \n",
    "    return corr\n",
    "\n",
    "def theta_cov_to_corr(theta, D):\n",
    "    mean, cov = param_list_to_mean_cov(theta, D=D)\n",
    "    corr = cov_to_corr(cov)\n",
    "    theta_corr = param_transform_full_cov((mean, corr))\n",
    "    return theta_corr\n",
    "\n",
    "def true_vs_estimated_tril(theta_true, theta_est, param_names, D, dpi=300,\n",
    "                      figsize=(20, 4), show=True, filename=None, font_size=12):\n",
    "    \"\"\" Plots a scatter plot with abline of the estimated posterior means vs true values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    theta_true: np.array\n",
    "        Array of true parameters.\n",
    "    theta_est: np.array\n",
    "        Array of estimated parameters.\n",
    "    param_names: list\n",
    "        List of parameter names for plotting.\n",
    "    D : int\n",
    "        Number of dimensions of parameters.\n",
    "    dpi: int, default:300\n",
    "        Dots per inch (dpi) for the plot.\n",
    "    figsize: tuple(int, int), default: (20,4)\n",
    "        Figure size.\n",
    "    show: boolean, default: True\n",
    "        Controls if the plot will be shown\n",
    "    filename: str, default: None\n",
    "        Filename if plot shall be saved\n",
    "    font_size: int, default: 12\n",
    "        Font size\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    idx = 0\n",
    "\n",
    "    # Plot settings\n",
    "    plt.rcParams['font.size'] = font_size\n",
    "\n",
    "    # Determine n_subplots dynamically\n",
    "    n_row = D+1\n",
    "    n_col = D\n",
    "\n",
    "    # Initialize figure\n",
    "    f, axarr = plt.subplots(n_row, n_col, figsize=figsize)\n",
    "        \n",
    "    # --- Plot true vs estimated posterior means on a single row --- #\n",
    "    \n",
    "    for i in range(n_row):\n",
    "        for j in range(n_col):\n",
    "            if j>(i-1) and i != 0:\n",
    "                axarr[i, j].axis('off')\n",
    "            else:\n",
    "                # Plot analytic vs estimated\n",
    "                axarr[i, j].scatter(theta_est[:, idx], theta_true[:, idx], color='black', alpha=0.4)\n",
    "\n",
    "                # get axis limits and set equal x and y limits\n",
    "                lower_lim = min(axarr[i, j].get_xlim()[0], axarr[i, j].get_ylim()[0])\n",
    "                upper_lim = max(axarr[i, j].get_xlim()[1], axarr[i, j].get_ylim()[1])\n",
    "                axarr[i, j].set_xlim((lower_lim, upper_lim))\n",
    "                axarr[i, j].set_ylim((lower_lim, upper_lim))\n",
    "                axarr[i, j].plot(axarr[i, j].get_xlim(), axarr[i, j].get_xlim(), '--', color='black')\n",
    "\n",
    "                # Compute NRMSE\n",
    "                rmse = np.sqrt(np.mean( (theta_est[:, idx] - theta_true[:, idx])**2 ))\n",
    "                nrmse = rmse / (theta_true[:, idx].max() - theta_true[:, idx].min())\n",
    "                axarr[i, j].text(0.1, 0.9, 'NRMSE={:.3f}'.format(nrmse),\n",
    "                             horizontalalignment='left',\n",
    "                             verticalalignment='center',\n",
    "                             transform=axarr[i, j].transAxes,\n",
    "                             size=10)\n",
    "\n",
    "                # Compute R2\n",
    "                #r2 = r2_score(theta_true[:, j], theta_est[:, j])\n",
    "                #axarr[j].text(0.1, 0.8, '$R^2$={:.3f}'.format(r2),\n",
    "                #             horizontalalignment='left',\n",
    "                #             verticalalignment='center',\n",
    "                #             transform=axarr[j].transAxes, \n",
    "                #             size=10)\n",
    "\n",
    "                if j == 0 and i == 0 or 0==0:\n",
    "                    # Label plot\n",
    "                    axarr[i, j].set_xlabel('Estimated')\n",
    "                    axarr[i, j].set_ylabel('True')\n",
    "                axarr[i, j].set_title(param_names[idx])\n",
    "                axarr[i, j].spines['right'].set_visible(False)\n",
    "                axarr[i, j].spines['top'].set_visible(False)\n",
    "                \n",
    "                idx += 1\n",
    "    \n",
    "    # Adjust spaces\n",
    "    f.tight_layout()\n",
    "    \n",
    "    if filename is not None:\n",
    "        f.savefig(filename)\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analytic posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analytic_joint_posterior_normal_inverse_wishart(X, mu_0, lamda_0, Psi_0, nu_0):\n",
    "    n_sim, n_obs, D = X.shape\n",
    "    mu_n = [None] * n_sim\n",
    "    lamda_n = [None] * n_sim\n",
    "    Psi_n = [None] * n_sim\n",
    "    nu_n = [None] * n_sim\n",
    "    \n",
    "    for i in range(n_sim):\n",
    "        x = X[i, :, :]\n",
    "        x_bar = np.mean(x, axis=0)\n",
    "        C = np.dot((x-x_bar).T, x-x_bar)\n",
    "        \n",
    "        mu_n[i] = (lamda_0 * mu_0 + n_obs*x_bar) / (lamda_0 + n_obs)\n",
    "        lamda_n[i] = lamda_0 + n_obs\n",
    "        nu_n[i] = nu_0 + n_obs\n",
    "        Psi_n[i] = Psi_0 + C + ((lamda_0*n_obs)/(lamda_0+n_obs)) * np.dot(x_bar-mu_0, (x_bar-mu_0).T)\n",
    "        \n",
    "    return mu_n, lamda_n, Psi_n, nu_n\n",
    "\n",
    "\n",
    "def marginal_posterior_normal_inverse_wishart(mu_n, lamda_n, Psi_n, nu_n):\n",
    "    D = mu_n[0].shape[0]\n",
    "    n_sim = len(mu_n)\n",
    "    \n",
    "    marginal_mu_distributions = [None] * n_sim\n",
    "    marginal_Sigma_distributions = [None] * n_sim\n",
    "\n",
    "    for i in range(n_sim):\n",
    "        # mu_p\n",
    "        marginal_mu_distributions[i] = stats.multivariate_t(\n",
    "            loc=mu_n[i], \n",
    "            shape=np.linalg.inv(Psi_n[i]) / (lamda_n[i]*(nu_n[i] - D + 1)), \n",
    "            df=nu_n[i] - D + 1\n",
    "        )\n",
    "        \n",
    "        # Sigma_p\n",
    "        marginal_Sigma_distributions[i] = stats.invwishart(nu_n[i], Psi_n[i])\n",
    "    \n",
    "    return marginal_mu_distributions, marginal_Sigma_distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversarial_diagnostics_mvn_full_cov(trainer, theta, x, mu_0=0.0, lamda_0=5, Psi_0=np.eye(5), nu_0=10, \n",
    "                                         print_plots=False, filename=None):\n",
    "    param_samples = trainer.network.sample(x, n_samples=200)\n",
    "    param_means = param_samples.mean(axis=0)\n",
    "\n",
    "    param_means = theta_cov_to_corr(param_means, D=D)\n",
    "\n",
    "    mu_n, lamda_n, Psi_n, nu_n = analytic_joint_posterior_normal_inverse_wishart(x, mu_0, lamda_0, Psi_0, nu_0)\n",
    "\n",
    "    marginal_mu_p, marginal_Sigma_p = marginal_posterior_normal_inverse_wishart(mu_n, lamda_n, Psi_n, nu_n)\n",
    "\n",
    "    mu_p_means = np.array([dist.loc for dist in marginal_mu_p])\n",
    "    Sigma_p_covs = np.array([marginal_Sigma_p[i].scale / (nu_n[i]-D-1) for i in range(len(marginal_Sigma_p))])\n",
    "\n",
    "    theta_analytical_posterior = param_transform_full_cov((mu_p_means, Sigma_p_covs))\n",
    "    theta_analytical_posterior = theta_cov_to_corr(theta_analytical_posterior, D=D)\n",
    "\n",
    "    param_names = [r'$\\mu_%i$'%i for i in range(1, D+1)] + \\\n",
    "    [r'$\\sigma_%i$'%(i+1) if i==j else r'cor$_{%i%i}$'%(i+1, j+1) for (i, j) in zip(*np.tril_indices(D))]\n",
    "\n",
    "    # analytical posterior\n",
    "    true_vs_estimated_tril(theta_analytical_posterior, param_means, param_names, D, figsize=(20,20), filename=f\"{filename}_true_analytic.{FILEFORMAT}\")\n",
    "\n",
    "        \n",
    "    \n",
    "    if print_plots:\n",
    "        s = np.array(trainer.network.summary_net(x))\n",
    "        sns.pairplot(pd.DataFrame(s, columns=['s_{}'.format(i) for i in range(1, s.shape[1]+1)]), kind=\"kde\")\n",
    "        if filename is not None:\n",
    "            plt.savefig(f\"{filename}_summary_response.{FILEFORMAT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (A0) Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_0o = 0.0\n",
    "lamda_0o = 5\n",
    "Psi_0o = np.eye(D)\n",
    "nu_0o = 10\n",
    "prior = NormalInverseWishartPrior(D=D, mu_0=mu_0o, lamda_0=lamda_0o, Psi_0=Psi_0o, nu_0=nu_0o)\n",
    "simulator = GaussianMeanCovSimulator()\n",
    "generative_model = GenerativeModel(prior, simulator, param_transform=param_transform_full_cov)\n",
    "\n",
    "theta, x = generative_model(200, 100)\n",
    "\n",
    "\n",
    "adversarial_diagnostics_mvn_full_cov(trainer, theta=theta, x=x, \n",
    "                                     #print_plots=True,\n",
    "                                    filename=\"plots/abf_mvn_full_baseline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (A1) - c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_0o = 2\n",
    "lamda_0o = 5\n",
    "Psi_0o = 1.5 * np.eye(D)\n",
    "nu_0o = 10\n",
    "prior = NormalInverseWishartPrior(D=D, mu_0=mu_0o, lamda_0=lamda_0o, Psi_0=Psi_0o, nu_0=nu_0o)\n",
    "simulator = GaussianMeanCovSimulator()\n",
    "generative_model = GenerativeModel(prior, simulator, param_transform=param_transform_full_cov)\n",
    "\n",
    "theta, x = generative_model(200, 100)\n",
    "\n",
    "\n",
    "adversarial_diagnostics_mvn_full_cov(trainer, theta=theta, x=x, \n",
    "                                     #print_plots=True,\n",
    "                                    filename=\"plots/abf_mvn_full_prior\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (A2)\n",
    "\n",
    "$\\boldsymbol{x}^{(i)}\\sim t_2(\\boldsymbol{\\mu}^{(i)}, \\boldsymbol{\\Sigma}^{(i)})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultivariateTSimulatorFullCov:\n",
    "    def __init__(self, df=2):\n",
    "        self.df = df\n",
    "\n",
    "    def simulate_data(self, mean, cov, n_obs):\n",
    "        x = stats.multivariate_t(loc=mean, shape=cov, df=self.df).rvs(n_obs)\n",
    "        return x\n",
    "\n",
    "    def generate_multiple_datasets(self, p_samples, n_obs):\n",
    "        mean, cov = p_samples\n",
    "        n_sim = mean.shape[0]\n",
    "        theta_dim = mean.shape[1]\n",
    "        sim_data = np.zeros((n_sim, n_obs, theta_dim))\n",
    "\n",
    "        for bi in range(n_sim):\n",
    "            sim_data[bi] = self.simulate_data(mean[bi], cov[bi], n_obs)\n",
    "        return sim_data.astype(np.float32)\n",
    "\n",
    "    def __call__(self, p_samples, n_obs):\n",
    "        return self.generate_multiple_datasets(p_samples, n_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_0o = 1.0\n",
    "lamda_0o = 5\n",
    "Psi_0o = np.eye(D)\n",
    "nu_0o = 10\n",
    "prior = NormalInverseWishartPrior(D=D, mu_0=mu_0o, lamda_0=lamda_0o, Psi_0=Psi_0o, nu_0=nu_0o)\n",
    "simulator = MultivariateTSimulatorFullCov(df=2)\n",
    "generative_model = GenerativeModel(prior, simulator, param_transform=param_transform_full_cov)\n",
    "\n",
    "theta, x = generative_model(200, 100)\n",
    "\n",
    "\n",
    "adversarial_diagnostics_mvn_full_cov(trainer, theta=theta, x=x, \n",
    "                                     #print_plots=True,\n",
    "                                    filename=\"plots/abf_mvn_full_simulator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (A3) Contamination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_0o = 0.0\n",
    "lamda_0o = 5\n",
    "Psi_0o = np.eye(D)\n",
    "nu_0o = 10\n",
    "prior = NormalInverseWishartPrior(D=D, mu_0=mu_0o, lamda_0=lamda_0o, Psi_0=Psi_0o, nu_0=nu_0o)\n",
    "simulator = GaussianMeanCovSimulator()\n",
    "generative_model = GenerativeModel(prior, simulator, param_transform=param_transform_full_cov)\n",
    "\n",
    "theta, x = generative_model(200, 100)\n",
    "\n",
    "n_sim, n_obs, data_dim = x.shape\n",
    "\n",
    "\n",
    "lamda = 0.5\n",
    "\n",
    "x = noisify_x(x, lamda = lamda,\n",
    "                      noise_sampler = partial(beta_noise_sampler, a=2, b=5, tau=1))\n",
    "\n",
    "adversarial_diagnostics_mvn_full_cov(trainer, theta=theta, x=x, \n",
    "                                     #print_plots=True,\n",
    "                                    filename=\"plots/abf_mvn_full_noise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary space: MD and MMD plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RERUN_GRID_EXPERIMENT=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamda_0 = 5\n",
    "nu_0 = 10\n",
    "\n",
    "n_loc = 101\n",
    "n_scale = 101\n",
    "prior_loc = np.linspace(-6.0, 6.0, num = n_loc)\n",
    "prior_scale = np.linspace(0.10, 5.90, num = n_scale)\n",
    "P1, P2 = np.meshgrid(prior_loc, prior_scale)\n",
    "\n",
    "if RERUN_GRID_EXPERIMENT:\n",
    "    _, x_star = trainer._forward_inference(200, 100)\n",
    "    s_star = np.array(trainer.network.summary_net(x_star))\n",
    "\n",
    "    MMD = np.zeros((n_scale, n_loc))\n",
    "    for i in tqdm(range(n_scale)):\n",
    "        for j in range(n_loc):\n",
    "            p1 = P1[i, j]\n",
    "            p2 = P2[i, j]\n",
    "            prior = NormalInverseWishartPrior(D=D, mu_0=p1, lamda_0=lamda_0, Psi_0=p2 * np.eye(D), nu_0=nu_0)\n",
    "            simulator = GaussianMeanCovSimulator()\n",
    "            generative_model = GenerativeModel(prior, simulator, param_transform=param_transform_full_cov)\n",
    "            _, x_o = generative_model(200, 100)\n",
    "            s_o = np.array(trainer.network.summary_net(x_o))\n",
    "            MMD[i, j] = float(maximum_mean_discrepancy(s_o, s_star, squared=False))\n",
    "    np.save(f\"data/MMD_grid_experiments/MVN_full_MMD_grid_prior.npy\", MMD)\n",
    "    \n",
    "MMD = np.load(f\"data/MMD_grid_experiments/MVN_full_MMD_grid_prior.npy\")\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.pcolor(P1, P2, MMD, shading=\"nearest\", rasterized=True)\n",
    "plt.xlabel(r\"$\\mu_0$\")\n",
    "plt.ylabel(r\"$\\tau_0$ (scale factor of $\\Psi_0$)\")\n",
    "plt.axhline(y=1.0, linestyle=\"--\", color=\"lightgreen\", alpha=.80)\n",
    "plt.axvline(x=0.0, linestyle=\"--\", color=\"lightgreen\", alpha=.80)\n",
    "\n",
    "plt.xticks([-5, 0, 5])\n",
    "\n",
    "#plt.plot(2, 1.5, linewidth=10, alpha=1.0, \n",
    "#         marker=\"o\", markersize=20, markeredgewidth=5.0, markeredgecolor=\"white\", markerfacecolor = color_codes[\"Prior location + scale\"]\n",
    "#        )\n",
    "#plt.plot(0, 2.5, linewidth=10, alpha=1.0, \n",
    "#         marker=\"o\", markersize=20, markeredgewidth=5.0, markeredgecolor=\"white\", markerfacecolor = color_codes[\"Prior scale\"]\n",
    "#        )\n",
    "#plt.plot(5, 1, linewidth=10, alpha=1.0, \n",
    "#         marker=\"o\", markersize=20, markeredgewidth=5.0, markeredgecolor=\"white\", markerfacecolor = color_codes[\"Prior location\"]\n",
    "#        )\n",
    "#\n",
    "#plt.plot(0, 1, linewidth=10, alpha=1.0, \n",
    "#         marker=\"o\", markersize=20, markeredgewidth=5.0, markeredgecolor=\"white\", markerfacecolor = color_codes[\"No MMS\"]\n",
    "#        )\n",
    "\n",
    "\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.set_xlabel(r\"$\\widehat{\\mathrm{rMMD}}$\")\n",
    "plt.savefig(f\"plots/abf_mvn_full_mmd_grid_prior.{FILEFORMAT}\", bbox_inches=\"tight\", dpi=DPI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RERUN_GRID_EXPERIMENT = False\n",
    "\n",
    "mu_0 = 0\n",
    "Psi_0 = np.eye(D)\n",
    "lamda_0 = 5\n",
    "nu_0 = 10\n",
    "\n",
    "\n",
    "n_df = 19\n",
    "n_lamda = 101\n",
    "df_list = np.arange(2, n_df+2)\n",
    "lamda_list = np.linspace(0.0, 1.0, num = n_lamda)\n",
    "\n",
    "df_grid, lamda_grid = np.meshgrid(df_list, lamda_list)\n",
    "\n",
    "if RERUN_GRID_EXPERIMENT:\n",
    "    _, x = trainer._forward_inference(200, 100)\n",
    "    z_psi = np.array(trainer.network.summary_net(x))\n",
    "\n",
    "    MMD = np.zeros((n_lamda, n_df))\n",
    "    for i in tqdm(range(n_lamda)):\n",
    "        for j in range(n_df):\n",
    "            df = df_grid[i, j]\n",
    "            lamda = lamda_grid[i, j]\n",
    "\n",
    "            prior = NormalInverseWishartPrior(D=D, mu_0=mu_0, lamda_0=lamda_0, Psi_0=Psi_0, nu_0=nu_0)\n",
    "            simulator = MultivariateTSimulatorFullCov(df=df)\n",
    "            generative_model = GenerativeModel(prior, simulator, param_transform=param_transform_full_cov)\n",
    "            \n",
    "            _, x_o = generative_model(200, 100)\n",
    "            x_o = noisify_x(x_o, lamda = lamda,\n",
    "                      noise_sampler = partial(beta_noise_sampler, a=2, b=5, tau=np.std(x_o)))\n",
    "            \n",
    "            s_o = np.array(trainer.network.summary_net(x_o))\n",
    "            MMD[i, j] = float(maximum_mean_discrepancy(s_o, z_psi, squared=False))\n",
    "    np.save(f\"data/MMD_grid_experiments/MVN_full_MMD_grid_likelihood_noise.npy\", MMD)\n",
    "    \n",
    "\n",
    "\n",
    "MMD = np.load(f\"data/MMD_grid_experiments/MVN_full_MMD_grid_likelihood_noise.npy\")\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.pcolor(lamda_list, df_list, MMD.T, shading=\"nearest\", rasterized=True, vmin=0)\n",
    "\n",
    "plt.xlabel(r\"$\\lambda$ (noise fraction)\")\n",
    "plt.ylabel(r\"simulator df\")\n",
    "\n",
    "plt.axvline(x=0.0, linestyle=\"--\", color=\"lightgreen\", alpha=1.00, linewidth=2)\n",
    "#plt.axhline(y=1.0, linestyle=\"--\", color=\"lightgreen\", alpha=1.00, linewidth=2)\n",
    "\n",
    "\n",
    "#plt.plot(0.5, 1, linewidth=10, alpha=1.0, \n",
    "#         marker=\"o\", markersize=20, markeredgewidth=5.0, markeredgecolor=\"white\", markerfacecolor = color_codes[\"Noise\"]\n",
    "#        )\n",
    "#plt.plot(0, 1, linewidth=10, alpha=1.0, \n",
    "#         marker=\"o\", markersize=20, markeredgewidth=5.0, markeredgecolor=\"white\", markerfacecolor = color_codes[\"No MMS\"]\n",
    "#        )\n",
    "#plt.plot(0, 10, linewidth=10, alpha=1.0, \n",
    "#         marker=MarkerStyle(\"o\"), markersize=20, markeredgewidth=5.0, markeredgecolor=\"white\", markerfacecolor = color_codes[\"Simulator\"]\n",
    "#        )\n",
    "\n",
    "plt.xlim(-0.02)\n",
    "#plt.ylim(0)\n",
    "plt.yticks([2, 10, 20])\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.set_xlabel(r\"$\\widehat{\\mathrm{rMMD}}$\")\n",
    "\n",
    "plt.savefig(f\"plots/abf_mvn_full_mmd_grid_likelihood_noise.{FILEFORMAT}\", bbox_inches=\"tight\", dpi=DPI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
