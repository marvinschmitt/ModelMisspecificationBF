{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebooks will replicate the results obtained by estimating our custom Covid-19 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.abspath(os.path.join('../BayesFlow')))\n",
    "\n",
    "from functools import partial\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.stats import binom, nbinom\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Conv1D, LSTM\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayesflow.networks import InvertibleNetwork, InvariantNetwork\n",
    "from bayesflow.amortizers import SingleModelAmortizer\n",
    "from bayesflow.trainers import ParameterEstimationTrainer\n",
    "from bayesflow.diagnostics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abf_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    \"axes.labelsize\" : 20,\n",
    "    \"xtick.labelsize\" : 16,\n",
    "    \"ytick.labelsize\" : 16,\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Times\"],\n",
    "})\n",
    "\n",
    "FILEFORMAT = 'pdf'\n",
    "DPI = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     23
    ]
   },
   "outputs": [],
   "source": [
    "confirmed_cases_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
    "recovered_cases_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv'\n",
    "dead_cases_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv'\n",
    "\n",
    "\n",
    "confirmed_cases = pd.read_csv(confirmed_cases_url, sep=',')\n",
    "recovered_cases = pd.read_csv(recovered_cases_url, sep=',')\n",
    "dead_cases = pd.read_csv(dead_cases_url, sep=',')\n",
    "\n",
    "\n",
    "date_data_begin = datetime.date(2020,3,1)\n",
    "date_data_end = datetime.date(2020,5,21)\n",
    "\n",
    "\n",
    "format_date = lambda date_py: '{}/{}/{}'.format(date_py.month, date_py.day,\n",
    "                                                 str(date_py.year)[2:4])\n",
    "date_formatted_begin = format_date(date_data_begin)\n",
    "date_formatted_end = format_date(date_data_end)\n",
    "\n",
    "cases_obs =  np.array(\n",
    "    confirmed_cases.loc[confirmed_cases[\"Country/Region\"] == \"Germany\", \n",
    "                        date_formatted_begin:date_formatted_end])[0]\n",
    "recovered_obs =  np.array(\n",
    "    recovered_cases.loc[recovered_cases[\"Country/Region\"] == \"Germany\", \n",
    "                        date_formatted_begin:date_formatted_end])[0]\n",
    "\n",
    "dead_obs =  np.array(\n",
    "    dead_cases.loc[dead_cases[\"Country/Region\"] == \"Germany\", \n",
    "                        date_formatted_begin:date_formatted_end])[0]\n",
    "\n",
    "data_germany = np.stack([cases_obs, recovered_obs, dead_obs]).T\n",
    "data_germany = np.diff(data_germany, axis=0)\n",
    "T_germany = data_germany.shape[0]\n",
    "N_germany = 83e6\n",
    "mean_g = np.mean(data_germany, axis=0)\n",
    "std_g = np.std(data_germany, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epidemiological Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     4,
     43,
     59
    ]
   },
   "outputs": [],
   "source": [
    "alpha_f = (0.7**2)*((1-0.7)/(0.17**2) - (1-0.7))\n",
    "beta_f = alpha_f*(1/0.7 - 1)\n",
    "\n",
    "\n",
    "def prior_sir():\n",
    "    \"\"\"\n",
    "    Implements batch sampling from a stationary prior over the parameters\n",
    "    of the non-stationary SIR model.\n",
    "    \"\"\"\n",
    "    \n",
    "    t1 = np.random.normal(loc=8, scale=3)\n",
    "    t2 = np.random.normal(loc=15, scale=1)\n",
    "    t3 = np.random.normal(loc=22, scale=1)\n",
    "    t4 = np.random.normal(loc=66, scale=1) \n",
    "    delta_t1 = np.random.lognormal(mean=np.log(3), sigma=0.3)\n",
    "    delta_t2 = np.random.lognormal(mean=np.log(3), sigma=0.3)\n",
    "    delta_t3 = np.random.lognormal(mean=np.log(3), sigma=0.3)\n",
    "    delta_t4 = np.random.lognormal(mean=np.log(3), sigma=0.3)\n",
    "    lambd0 = np.random.lognormal(mean=np.log(1.2), sigma=0.5)\n",
    "    lambd1 = np.random.lognormal(mean=np.log(0.6), sigma=0.5)\n",
    "    lambd2 = np.random.lognormal(mean=np.log(0.3), sigma=0.5)\n",
    "    lambd3 = np.random.lognormal(mean=np.log(0.1), sigma=0.5)\n",
    "    lambd4 = np.random.lognormal(mean=np.log(0.1), sigma=0.5)\n",
    "    mu = np.random.lognormal(mean=np.log(1/8), sigma=0.2)\n",
    "    f_i = np.random.beta(a=alpha_f, b=beta_f)\n",
    "    phi_i = stats.vonmises(kappa=0.01).rvs()\n",
    "    f_r = np.random.beta(a=alpha_f, b=beta_f)\n",
    "    phi_r = stats.vonmises(kappa=0.01).rvs()\n",
    "    f_d = np.random.beta(a=alpha_f, b=beta_f)\n",
    "    phi_d = stats.vonmises(kappa=0.01).rvs()\n",
    "    D_i = np.random.lognormal(mean=np.log(8), sigma=0.2)\n",
    "    D_r = np.random.lognormal(mean=np.log(8), sigma=0.2)\n",
    "    D_d = np.random.lognormal(mean=np.log(8), sigma=0.2)\n",
    "    E0 = np.random.gamma(shape=2, scale=30)\n",
    "    scale_I = np.random.gamma(shape=1, scale=5)\n",
    "    scale_R = np.random.gamma(shape=1, scale=5)\n",
    "    scale_D = np.random.gamma(shape=1, scale=5)\n",
    "    return [t1, t2, t3, t4, delta_t1, delta_t2, delta_t3, delta_t4, \n",
    "            lambd0, lambd1, lambd2, lambd3, lambd4, mu, \n",
    "            f_i, phi_i, f_r, phi_r, f_d, phi_d, \n",
    "            D_i, D_r, D_d, E0, scale_I, scale_R, scale_D]\n",
    "\n",
    "\n",
    "def prior_secir():\n",
    "    \"\"\"\n",
    "    Implements batch sampling from a stationary prior over the parameters\n",
    "    of the non-stationary SIR model.\n",
    "    \"\"\"\n",
    "    \n",
    "    alpha = np.random.uniform(low=0.005, high=0.9)\n",
    "    beta = np.random.lognormal(mean=np.log(0.25), sigma=0.3)\n",
    "    gamma = np.random.lognormal(mean=np.log(1/6.5), sigma=0.5)\n",
    "    eta = np.random.lognormal(mean=np.log(1/3.2), sigma=0.3)\n",
    "    theta = np.random.uniform(low=1/14, high=1/3)\n",
    "    delta = np.random.uniform(low=0.01, high=0.3)\n",
    "    d = np.random.uniform(low=1/14, high=1/3)\n",
    "    return [alpha, beta, gamma, eta, theta, delta, d]\n",
    "\n",
    "\n",
    "def calc_lambda_array(sim_lag, lambd0, lambd1, lambd2, lambd3, lambd4, \n",
    "                      t1, t2, t3, t4, delta_t1, delta_t2, delta_t3, delta_t4, T):\n",
    "    \"\"\"Computes the array of time-varying contact rates/transimission probabilities.\"\"\"\n",
    "    \n",
    "    # Array of initial lambdas\n",
    "    lambd0_arr = np.array([lambd0] * (t1+sim_lag))\n",
    "    \n",
    "    # Compute lambd1 array\n",
    "    if delta_t1 == 1:\n",
    "        lambd1_arr = np.array([lambd1] * (t2-t1))\n",
    "    else:\n",
    "        lambd1_arr = np.linspace(lambd0, lambd1, delta_t1)\n",
    "        lambd1_arr = np.append(lambd1_arr, [lambd1] * (t2-t1-delta_t1))\n",
    "        \n",
    "    # Compute lambd2 array\n",
    "    if delta_t2 == 1:\n",
    "        lambd2_arr = np.array([lambd2] * (t3-t2))\n",
    "    else:\n",
    "        lambd2_arr = np.linspace(lambd1, lambd2, delta_t2)\n",
    "        lambd2_arr = np.append(lambd2_arr, [lambd2] * (t3-t2-delta_t2))\n",
    "        \n",
    "    # Compute lambd3 array\n",
    "    if delta_t3 == 1:\n",
    "        lambd3_arr = np.array([lambd3] * (t4-t3))\n",
    "    else:\n",
    "        lambd3_arr = np.linspace(lambd3, lambd4, delta_t3)\n",
    "        lambd3_arr = np.append(lambd3_arr, [lambd3] * (t4-t3-delta_t3))\n",
    "        \n",
    "    # Compute lambd4 array\n",
    "    if delta_t4 == 1:\n",
    "        lambd4_arr = np.array([lambd4] * (T-t4))\n",
    "    else:\n",
    "        lambd4_arr = np.linspace(lambd3, lambd4, delta_t4)\n",
    "        lambd4_arr = np.append(lambd4_arr, [lambd4] * (T-t4-delta_t4))\n",
    "    \n",
    "    return np.r_[lambd0_arr, lambd1_arr, lambd2_arr, lambd3_arr, lambd4_arr]\n",
    "\n",
    "    \n",
    "def non_stationary_SEICR(params_sir, params_secir, N, T, sim_diff=16, observation_model=True):\n",
    "    \"\"\"\n",
    "    Performs a forward simulation from the stationary SIR model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract parameters \n",
    "    t1, t2, t3, t4, delta_t1, delta_t2, delta_t3, delta_t4, lambd0, lambd1, lambd2, lambd3, lambd4, mu, f_i, phi_i, f_r, phi_r, f_d, phi_d, delay_i, delay_r, delay_d, E0, scale_I, scale_R, scale_D = params_sir\n",
    "    alpha, beta, gamma, eta, theta, delta, d = params_secir\n",
    "    \n",
    "    # Round integer parameters\n",
    "    t1, t2, t3, t4 = int(round(t1)), int(round(t2)), int(round(t3)), int(round(t4))\n",
    "    delta_t1, delta_t2, delta_t3, delta_t4 = int(round(delta_t1)), int(round(delta_t2)), int(round(delta_t3)), int(round(delta_t4))\n",
    "    E0 = max(1, np.round(E0)) \n",
    "    delay_i = int(round(delay_i)) \n",
    "    delay_r = int(round(delay_r)) \n",
    "    delay_d = int(round(delay_d)) \n",
    "    \n",
    "    # Impose constraints\n",
    "    assert sim_diff > delay_i\n",
    "    assert sim_diff > delay_r\n",
    "    assert sim_diff > delay_d\n",
    "    assert t1 > 0 and t2 > 0 and t3 > 0 and t4 > 0\n",
    "    assert t1 < t2 < t3 < t4\n",
    "    assert delta_t1 > 0 and delta_t2 > 0 and delta_t3 > 0 and delta_t4 > 0\n",
    "    assert t2 - t1 >= delta_t1 and t3 - t2 >= delta_t2 and t4-t3 >= delta_t3 and T-t4 >= delta_t4\n",
    "\n",
    "    # Calculate lambda arrays\n",
    "    # Lambda0 is the initial contact rate which will be consecutively\n",
    "    # reduced via the government measures\n",
    "    sim_lag = sim_diff - 1\n",
    "    lambd_arr = calc_lambda_array(sim_lag, lambd0, lambd1, lambd2, lambd3, lambd4, \n",
    "                                  t1, t2, t3, t4, delta_t1, delta_t2, delta_t3, delta_t4, T)\n",
    " \n",
    "    # Initial conditions\n",
    "    S, E, C, I, R, D = [N-E0], [E0], [0], [0], [0], [0]\n",
    "    \n",
    "    # Containers\n",
    "    I_news = []\n",
    "    R_news = []\n",
    "    D_news = []\n",
    "    \n",
    "    # Reported new cases\n",
    "    I_data = np.zeros(T)\n",
    "    R_data = np.zeros(T)\n",
    "    D_data = np.zeros(T)\n",
    "    fs_i = np.zeros(T)\n",
    "    fs_r = np.zeros(T)\n",
    "    fs_d = np.zeros(T)\n",
    " \n",
    "    # Simulate T-1 tiemsteps\n",
    "    for t in range(T+sim_lag):\n",
    "        \n",
    "        # Calculate new exposed cases\n",
    "        E_new = lambd_arr[t] * ((C[t] + beta*I[t])/N)*S[t]\n",
    "    \n",
    "        # Remove exposed from susceptible\n",
    "        S_t = S[t] - E_new\n",
    "        \n",
    "        # Calculate current exposed by adding new exposed and\n",
    "        # subtracting the exposed becoming carriers.\n",
    "        E_t = E[t] + E_new - gamma*E[t]\n",
    "        \n",
    "        # Calculate current carriers by adding the new exposed and subtracting\n",
    "        # those who will develop symptoms and become detected and those who\n",
    "        # will go through the disease asymptomatically.\n",
    "        C_t = C[t] + gamma*E[t] - (1-alpha)*eta*C[t] - alpha*theta*C[t]\n",
    "        \n",
    "        # Calculate current infected by adding the symptomatic carriers and \n",
    "        # subtracting the dead and recovered. The newly infected are just the \n",
    "        # carriers who get detected.\n",
    "        I_t = I[t] + (1-alpha)*eta*C[t] - (1-delta)*mu*I[t] - delta*d*I[t]\n",
    "        I_new = (1-alpha)*eta*C[t]\n",
    "        \n",
    "        # Calculate current recovered by adding the symptomatic and asymptomatic\n",
    "        # recovered. The newly recovered are only the detected recovered\n",
    "        R_t = R[t] + alpha*theta*C[t] + (1-delta)*mu*I[t]\n",
    "        R_new = (1-delta)*mu*I[t]\n",
    "        \n",
    "        # Calculate the current dead\n",
    "        D_t = D[t] + delta*d*I[t]\n",
    "        D_new = delta*d*I[t]\n",
    "        \n",
    "        # Ensure some numerical onstraints\n",
    "        S_t = np.clip(S_t, 0, N)\n",
    "        E_t = np.clip(E_t, 0, N)\n",
    "        C_t = np.clip(C_t, 0, N)\n",
    "        I_t = np.clip(I_t, 0, N)\n",
    "        R_t = np.clip(R_t, 0, N)\n",
    "        D_t = np.clip(D_t, 0, N)\n",
    "        \n",
    "        # Keep track of process over time\n",
    "        S.append(S_t)\n",
    "        E.append(E_t)\n",
    "        C.append(C_t)\n",
    "        I.append(I_t)\n",
    "        R.append(R_t)\n",
    "        D.append(D_t)\n",
    "        I_news.append(I_new)\n",
    "        R_news.append(R_new)\n",
    "        D_news.append(D_new)\n",
    "        \n",
    "        # From here, start adding new cases with delay D\n",
    "        # Note, we assume the same delay\n",
    "        if t >= sim_lag:\n",
    "            \n",
    "            # Compute lags and add to data arrays\n",
    "            fs_i[t-sim_lag] = (1-f_i)*(1 - np.abs( np.sin( (np.pi/7) * (t-sim_lag) - 0.5*phi_i)) )\n",
    "            fs_r[t-sim_lag] = (1-f_r)*(1 - np.abs( np.sin( (np.pi/7) * (t-sim_lag) - 0.5*phi_r)) )\n",
    "            fs_d[t-sim_lag] = (1-f_d)*(1 - np.abs( np.sin( (np.pi/7) * (t-sim_lag) - 0.5*phi_d)) )\n",
    "            I_data[t-sim_lag] = I_news[t-delay_i]\n",
    "            R_data[t-sim_lag] = R_news[t-delay_r]\n",
    "            D_data[t-sim_lag] = D_news[t-delay_d]\n",
    "            \n",
    "    # Compute weekly modulation\n",
    "    I_data = (1-fs_i) * I_data\n",
    "    R_data = (1-fs_r) * R_data\n",
    "    D_data = (1-fs_d) * D_data\n",
    "    \n",
    "    # Add noise\n",
    "    I_data = stats.t(df=4, loc=I_data, scale=np.sqrt(I_data)*scale_I).rvs()\n",
    "    R_data = stats.t(df=4, loc=R_data, scale=np.sqrt(R_data)*scale_R).rvs()\n",
    "    D_data = stats.t(df=4, loc=D_data, scale=np.sqrt(D_data)*scale_D).rvs()\n",
    "    \n",
    "    if observation_model:\n",
    "        return np.stack((I_data, R_data, D_data)).T\n",
    "    return np.stack((S, E, I, C, R, D)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def data_generator(n_sim, n_obs, N=None, sim_diff=21, N_min=10000, N_max=70000000):\n",
    "    \"\"\"\n",
    "    Runs the forward model 'batch_size' times by first sampling fromt the prior\n",
    "    theta ~ p(theta) and running x ~ p(x|theta).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Variable size N\n",
    "    if N is None:\n",
    "        N = np.random.randint(N_min, N_max)\n",
    "        \n",
    "    # Generate data\n",
    "    # x is a np.ndarray of shape (batch_size, n_obs, x_dim)\n",
    "    x = []\n",
    "    theta = []\n",
    "    for i in range(n_sim):\n",
    "        \n",
    "        # Reject meaningless simulaitons\n",
    "        x_i = None\n",
    "        while x_i is None:\n",
    "            try:\n",
    "                theta1 = prior_sir()\n",
    "                theta2 = prior_secir()\n",
    "                x_i = non_stationary_SEICR(theta1, theta2, N, n_obs, sim_diff=sim_diff)\n",
    "                x_i = (x_i - mean_g) / std_g\n",
    "            except:\n",
    "                 pass\n",
    "        # Simulate SECIR\n",
    "        x.append(x_i)\n",
    "        theta.append(theta1 + theta2)\n",
    "    x = np.array(x)\n",
    "    theta = np.array(theta)\n",
    "\n",
    "    # Convert to tensor, if specified \n",
    "    return theta.astype(np.float32), x.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names = [r'$t_1$', r'$t_2$', r'$t_3$', r'$t_4$',\n",
    "               r'$\\Delta t_1$', r'$\\Delta t_2$', r'$\\Delta t_3$', r'$\\Delta t_4$',\n",
    "               r'$\\lambda_0$', r'$\\lambda_1$', r'$\\lambda_2$', r'$\\lambda_3$', r'$\\lambda_4$', \n",
    "               r'$\\mu$', r'$f_I$', r'$\\phi_I$',  r'$f_R$', r'$\\phi_R$',  \n",
    "               r'$f_D$', r'$\\phi_D$',\n",
    "               r'$L_I$', r'$L_R$', r'$L_D$', r'$E_0$', r'$\\sigma_I$', r'$\\sigma_R$', r'$\\sigma_D$', \n",
    "               r'$\\alpha$', r'$\\beta$', r'$\\gamma$',\n",
    "               r'$\\eta$', r'$\\theta$', r'$\\delta$', r'$d$']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen = partial(data_generator, N=N_germany, sim_diff=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     13
    ]
   },
   "outputs": [],
   "source": [
    "class MultiConvLayer(tf.keras.Model):\n",
    "    \"\"\"Implements an inception-inspired conv layer using different kernel sizes\"\"\"\n",
    "    def __init__(self, n_filters=32, strides=1):\n",
    "        super(MultiConvLayer, self).__init__()\n",
    "        \n",
    "        self.convs = [\n",
    "            Conv1D(n_filters//2, kernel_size=f, strides=strides, \n",
    "                                   padding='causal', activation='relu', kernel_initializer='glorot_uniform')\n",
    "            for f in range(2, 8)\n",
    "        ]\n",
    "        self.dim_red = Conv1D(n_filters, 1, 1, activation='relu', kernel_initializer='glorot_uniform')\n",
    "        \n",
    "    def call(self, x):\n",
    "        \"\"\"x is a timeseries of dimensions B timestamps, n_features\"\"\"\n",
    "        \n",
    "        out = tf.concat([conv(x) for conv in self.convs], axis=-1)\n",
    "        out = self.dim_red(out)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "class MultiConvNet(tf.keras.Model):\n",
    "    \"\"\"Implements an inception-inspired conv layer using different kernel sizes\"\"\"\n",
    "    def __init__(self, n_layers=3, n_filters=64, strides=1):\n",
    "        super(MultiConvNet, self).__init__()\n",
    "        \n",
    "        self.net = Sequential([\n",
    "            MultiConvLayer(n_filters, strides)\n",
    "            for _ in range(n_layers)\n",
    "        ])\n",
    "        \n",
    "        self.lstm = LSTM(n_filters)\n",
    "        \n",
    "    def call(self, x, **args):\n",
    "        \"\"\"x is a timeseries of dimensions B timestamps, n_features\"\"\"\n",
    "        \n",
    "        out = self.net(x)\n",
    "        out = self.lstm(out)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "class SummaryNet(tf.keras.Model):\n",
    "    def __init__(self, n_summary=192):\n",
    "        super(SummaryNet, self).__init__()\n",
    "        self.net_I = MultiConvNet(n_filters=n_summary//3)\n",
    "        self.net_R = MultiConvNet(n_filters=n_summary//3)\n",
    "        self.net_D = MultiConvNet(n_filters=n_summary//3)\n",
    "    \n",
    "    def call(self, x, **args):\n",
    "        \"\"\"x is a timeseries of dimensions B timestamps, n_features\"\"\"\n",
    "        \n",
    "        x = tf.split(x, 3, axis=-1)\n",
    "        x_i = self.net_I(x[0])\n",
    "        x_r = self.net_R(x[1])\n",
    "        x_d = self.net_D(x[2])\n",
    "        return tf.concat([x_i, x_r, x_d], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-07 19:30:44.594666: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-12-07 19:30:44.594887: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "meta_dict={\n",
    "    'n_coupling_layers': 6,\n",
    "    's_args': {\n",
    "        'units': [192, 192, 192],\n",
    "        'activation': 'elu',\n",
    "        'initializer': 'glorot_uniform',\n",
    "    },\n",
    "    't_args': {\n",
    "        'units': [192, 192, 192],\n",
    "        'activation': 'elu',\n",
    "        'initializer': 'glorot_uniform',\n",
    "    },\n",
    "    'alpha': 1.9,\n",
    "    'use_permutation': True,\n",
    "    'use_act_norm': True,\n",
    "    'n_params': len(param_names),\n",
    "}\n",
    "\n",
    "\n",
    "summary_net = SummaryNet()\n",
    "inference_net = InvertibleNetwork(meta_dict)\n",
    "amortizer = SingleModelAmortizer(inference_net, summary_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Networks loaded from export_ckpt/mmd/covid19/ckpt-50\n"
     ]
    }
   ],
   "source": [
    "starter_learning_rate = 0.0005\n",
    "learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    starter_learning_rate,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.99,\n",
    "    staircase=True\n",
    ")\n",
    "\n",
    "\n",
    "trainer = ParameterEstimationTrainer(\n",
    "    network=amortizer, \n",
    "    generative_model=data_gen,\n",
    "    loss=mmd_kl_loss,\n",
    "    learning_rate=learning_rate,\n",
    "    checkpoint_path=f'export_ckpt/mmd/covid19',\n",
    "    max_to_keep=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#losses = trainer.train_online(epochs=50, iterations_per_epoch=1000, batch_size=64, n_obs=T_germany)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blind MM analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from abf_functions import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/COVID_model_data/data_model_star_test.pkl', 'rb') as f:\n",
    "    x_star_test = pickle.load(f)['x']\n",
    "with open('data/COVID_model_data/data_model_1.pkl', 'rb') as f:\n",
    "    x_1 = pickle.load(f)['x']\n",
    "with open('data/COVID_model_data/data_model_2.pkl', 'rb') as f:\n",
    "    x_2 = pickle.load(f)['x']\n",
    "with open('data/COVID_model_data/data_model_3.pkl', 'rb') as f:\n",
    "    x_3 = pickle.load(f)['x']\n",
    "\n",
    "_, x_star = trainer._forward_inference(1000, T_germany)\n",
    "\n",
    "s_star_test = np.array(trainer.network.summary_net(x_star_test))\n",
    "s_1 = np.array(trainer.network.summary_net(x_1))\n",
    "s_2 = np.array(trainer.network.summary_net(x_2))\n",
    "s_3 = np.array(trainer.network.summary_net(x_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_x = np.array(trainer.network.summary_net(x_star))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in [\"s_star_test\", \"s_1\", \"s_2\", \"s_3\"]:\n",
    "    print(f\"{s}: MMD={float(maximum_mean_discrepancy(globals()[s], z_x, unbiased=True)):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 100\n",
    "MMD = np.empty(K)\n",
    "for k in range(K):\n",
    "    _, x = trainer._forward_inference(1, T_germany)\n",
    "    s  = np.array(trainer.network.summary_net(x))\n",
    "    MMD[k] = float(maximum_mean_discrepancy(s, z_x, unbiased=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(MMD)\n",
    "plt.xlim(0)\n",
    "plt.title(\"Distribution of 100 MMDs with B=1 data from the trainer's generative model\")\n",
    "plt.axvline(x=MMD_germany_standardized, color=\"red\", linestyle=\"dashed\")\n",
    "plt.xlabel(r\"$\\widehat{MMD}^2_u$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_germany_tensor = data_germany[np.newaxis, ...]\n",
    "data_germany_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardized\n",
    "data_germany_tensor = data_germany[np.newaxis, ...]\n",
    "data_germany_tensor.shape\n",
    "data_germany_standardized = (data_germany_tensor - mean_g) / std_g\n",
    "s_germany_standardized = np.array(trainer.network.summary_net(data_germany_standardized))\n",
    "MMD_germany_standardized = float(maximum_mean_discrepancy(s_germany_standardized, z_x, unbiased=True))\n",
    "print(\"standardized: MMD =\", MMD_germany_standardized)\n",
    "s_germany_standardized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non_standardized\n",
    "s_germany = np.array(trainer.network.summary_net(data_germany_tensor))\n",
    "print(\"non-standardized: MMD =\", float(maximum_mean_discrepancy(s_germany, z_x, unbiased=True)))\n",
    "s_germany.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmd2_null = mmd_permutation(s_germany_standardized, z_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(mmd2_null)\n",
    "plt.xlim(0)\n",
    "plt.title(\"Permutation Test Germany Data standardized\")\n",
    "plt.axvline(x=MMD_germany_standardized, color=\"red\", linestyle=\"dashed\")\n",
    "plt.xlabel(r\"$\\widehat{MMD}^2_u$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, x = trainer._forward_inference(10000, T_germany)\n",
    "s = np.array(trainer.network.summary_net(x))\n",
    "\n",
    "K = 192\n",
    "\n",
    "pca = PCA(K)\n",
    "pca.fit(s)\n",
    "\n",
    "cumsum_explained_variance_ratio = np.cumsum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, K+1), cumsum_explained_variance_ratio, linewidth=4, color=\"dodgerblue\")\n",
    "plt.xlabel(\"Number of PCs\")\n",
    "plt.ylabel(r\"$\\sum R^2$\")\n",
    "plt.ylim(0)\n",
    "plt.xlim(0, 200)\n",
    "plt.plot([0, 192], [1, 1], linestyle=\"dashed\", color=\"grey\", linewidth=2)\n",
    "plt.plot([40, 40], [0, 0.95], linestyle=\"dashed\", color=\"darkgoldenrod\")\n",
    "#plt.plot([0, 40], [0.95, 0.95], linestyle=\"dashed\", color=\"darkgoldenrod\")\n",
    "#plt.text(-18, 0.9, r\"\\textbf{0.95}\", color=\"darkgoldenrod\", size=16)\n",
    "plt.grid()\n",
    "sns.despine()\n",
    "plt.savefig(f\"plots/COVID_PCA_explained_variance.{FILEFORMAT}\", bbox_inches=\"tight\", dpi=DPI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(cumsum_explained_variance_ratio > 0.95)yticks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumsum_explained_variance_ratio[40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data from trainer's generative model\n",
    "_, x = trainer._forward_inference(1000, T_germany)\n",
    "s = np.array(trainer.network.summary_net(x))\n",
    "\n",
    "# Fit PCA to data from trainer\n",
    "pca = PCA(2)\n",
    "pca.fit(s)\n",
    "\n",
    "\n",
    "# Generate more data from trainer's generative model\n",
    "_, x_star = trainer._forward_inference(1000, T_germany)\n",
    "s_star = trainer.network.summary_net(x_star)\n",
    "\n",
    "# Project all candidate data onto the Principal Components\n",
    "s_star_proj = pca.transform(s_star)\n",
    "s_star_test_proj = pca.transform(s_star_test)\n",
    "s_1_proj = pca.transform(s_1)\n",
    "s_2_proj = pca.transform(s_2)\n",
    "s_3_proj = pca.transform(s_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = [s_star_proj, s_star_test_proj, s_1_proj, s_2_proj, s_3proj]\n",
    "TASK_NAMES = ['x_star', 'x_star_test', 'x_1', 'x_2', 'x_3']\n",
    "\n",
    "DF = (pd.DataFrame(s, \n",
    "                     columns=[r'$Proj_{%i}$'%i for i in range(1, 3)]) for s in S)\n",
    "\n",
    "df = pd.concat(DF,\n",
    "              keys=TASK_NAMES,\n",
    "              names=['Model', None]\n",
    "              ).reset_index(level=0)\n",
    "\n",
    "g = sns.PairGrid(df, hue=\"Model\", palette=['red', 'orange', 'green', 'blue', 'brown'], height=3)\n",
    "\n",
    "g.map_upper(plt.scatter, alpha=0.1)\n",
    "g.map_diag(sns.kdeplot)\n",
    "g.map_lower(sns.kdeplot, alpha=0.50)\n",
    "\n",
    "g.add_legend()\n",
    "plt.setp(g._legend.get_title(), fontsize=16)\n",
    "plt.setp(g._legend.get_texts(), fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate PCAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data from trainer's generative model\n",
    "_, x_star = trainer._forward_inference(1000, T_germany)\n",
    "s_star = trainer.network.summary_net(x_star)\n",
    "\n",
    "# Fit and project all data on separate PCAs based on them\n",
    "s_star_proj = PCA(2).fit_transform(s_star)\n",
    "s_star_test_proj = PCA(2).fit_transform(s_star_test)\n",
    "s_1_proj = PCA(2).fit_transform(s_1)\n",
    "s_2_proj = PCA(2).fit_transform(s_2)\n",
    "s_3_proj = PCA(2).fit_transform(s_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = [s_star_proj, s_star_test_proj, s_1_proj, s_2_proj, s_3_proj]\n",
    "TASK_NAMES = ['x_star', 'x_star_test', 'x_1', 'x_2', 'x_3']\n",
    "\n",
    "DF = (pd.DataFrame(s, \n",
    "                     columns=[r'$Proj_{%i}$'%i for i in range(1, 3)]) for s in S)\n",
    "\n",
    "df = pd.concat(DF,\n",
    "              keys=TASK_NAMES,\n",
    "              names=['Model', None]\n",
    "              ).reset_index(level=0)\n",
    "\n",
    "g = sns.PairGrid(df, hue=\"Model\", palette=['red', 'orange', 'green', 'blue', 'brown'], height=3)\n",
    "\n",
    "g.map_upper(plt.scatter, alpha=0.1)\n",
    "g.map_diag(sns.kdeplot)\n",
    "g.map_lower(sns.kdeplot, alpha=0.50)\n",
    "\n",
    "g.add_legend()\n",
    "plt.setp(g._legend.get_title(), fontsize=16)\n",
    "plt.setp(g._legend.get_texts(), fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/COVID_model_data/data_model_star_test.pkl', 'rb') as f:\n",
    "    x_star_test = pickle.load(f)['x']\n",
    "with open('data/COVID_model_data/data_model_1.pkl', 'rb') as f:\n",
    "    x_1 = pickle.load(f)['x']\n",
    "with open('data/COVID_model_data/data_model_2.pkl', 'rb') as f:\n",
    "    x_2 = pickle.load(f)['x']\n",
    "with open('data/COVID_model_data/data_model_3.pkl', 'rb') as f:\n",
    "    x_3 = pickle.load(f)['x']\n",
    "\n",
    "_, x_star = trainer._forward_inference(1000, T_germany)\n",
    "s_star = np.array(trainer.network.summary_net(x_star))\n",
    "\n",
    "s_star_test = np.array(trainer.network.summary_net(x_star_test))\n",
    "s_1 = np.array(trainer.network.summary_net(x_1))\n",
    "s_2 = np.array(trainer.network.summary_net(x_2))\n",
    "s_3 = np.array(trainer.network.summary_net(x_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MMD_star = float(maximum_mean_discrepancy(s_star_test, s_star, unbiased=True))\n",
    "MMD_1 = float(maximum_mean_discrepancy(s_1, s_star, unbiased=True))\n",
    "MMD_2 = float(maximum_mean_discrepancy(s_2, s_star, unbiased=True))\n",
    "MMD_3 = float(maximum_mean_discrepancy(s_3, s_star, unbiased=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MMD_bootstrap(x_star, x_test, N_BOOTSTRAP_ITERATIONS=10):\n",
    "    n_star = x_star.shape[0]\n",
    "    n_test = x_test.shape[0]\n",
    "    \n",
    "    MMD_bootstrap = np.empty(N_BOOTSTRAP_ITERATIONS)\n",
    "\n",
    "    for i in tqdm(range(N_BOOTSTRAP_ITERATIONS)):\n",
    "        idx_star = np.random.randint(0, n_star, size=n_star)\n",
    "        idx_test = np.random.randint(0, n_test, size=n_test)\n",
    "        \n",
    "        x_star_bootstrap = x_star[idx_star]\n",
    "        x_test_bootstrap = x_test[idx_test]\n",
    "        \n",
    "        s_star_bootstrap = np.array(trainer.network.summary_net(x_star_bootstrap))\n",
    "        s_test_bootstrap = np.array(trainer.network.summary_net(x_test_bootstrap))\n",
    "        \n",
    "        MMD_bootstrap[i] = float(maximum_mean_discrepancy(s_star_bootstrap, s_test_bootstrap, unbiased=True))\n",
    "        \n",
    "    return MMD_bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MMD_1_bootstrap = MMD_bootstrap(x_star, x_1, N_BOOTSTRAP_ITERATIONS=100)\n",
    "#MMD_2_bootstrap = MMD_bootstrap(x_star, x_2, N_BOOTSTRAP_ITERATIONS=100)\n",
    "#MMD_3_bootstrap = MMD_bootstrap(x_star, x_3, N_BOOTSTRAP_ITERATIONS=100)\n",
    "#MMD_4_bootstrap = MMD_bootstrap(x_star, x_4, N_BOOTSTRAP_ITERATIONS=100)\n",
    "\n",
    "#np.save(\"data/MMD_bootstrapping/MMD_1_bootstrap.npy\", MMD_1_bootstrap)\n",
    "#np.save(\"data/MMD_bootstrapping/MMD_2_bootstrap.npy\", MMD_2_bootstrap)\n",
    "#np.save(\"data/MMD_bootstrapping/MMD_3_bootstrap.npy\", MMD_3_bootstrap)\n",
    "#np.save(\"data/MMD_bootstrapping/MMD_4_bootstrap.npy\", MMD_4_bootstrap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MMD_star_bootstrap = np.load(\"data/MMD_bootstrapping/MMD_star_bootstrap.npy\")\n",
    "MMD_1_bootstrap = np.load(\"data/MMD_bootstrapping/MMD_1_bootstrap.npy\")\n",
    "MMD_2_bootstrap = np.load(\"data/MMD_bootstrapping/MMD_2_bootstrap.npy\")\n",
    "MMD_3_bootstrap = np.load(\"data/MMD_bootstrapping/MMD_3_bootstrap.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_CI(x, ci_area=0.95):\n",
    "    q_lower = round((1.0 - ci_area) / 2, 5)\n",
    "    q_upper = round(1.0 - q_lower, 5)\n",
    "    return np.quantile(x, q_lower), np.quantile(x, q_upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MMDs_bootstrap = [MMD_star_bootstrap, MMD_1_bootstrap, MMD_2_bootstrap, MMD_3_bootstrap]\n",
    "\n",
    "for i, MMD_b in enumerate(MMDs_bootstrap, 1):\n",
    "    lower_bound, upper_bound = calculate_CI(MMD_b, ci_area=0.95)\n",
    "    median = np.median(MMD_b)\n",
    "    print(f\"M{i}: {median:.3f} [{lower_bound:.3f}, {upper_bound:.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MMDs = [MMD_star, MMD_1, MMD_2, MMD_3]\n",
    "MMD_bootstraps = [MMD_star_bootstrap, MMD_1_bootstrap, MMD_2_bootstrap, MMD_3_bootstrap]\n",
    "colors = [\"red\", \"firebrick\", \"orange\", \"blue\"]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for i in range(4):\n",
    "    sns.kdeplot(MMD_bootstraps[i], ax=ax, label=f\"M{i}\")\n",
    "    ax.legend()\n",
    "    ax.set_title(r\"$\\widehat{MMD}^2_u$ for 100 bootstraps of $x^*$ and $x_{test}$\")\n",
    "    ax.set_xlabel(r\"$\\widehat{MMD}^2_u$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MMD_H0_single_instance(trainer, n_simulations, n_obs, n_simulations_reference=1000, plot=False):\n",
    "    _, x_star = trainer._forward_inference(n_simulations_reference, n_obs)\n",
    "    _, x_star_prime = trainer._forward_inference(n_simulations, n_obs)\n",
    "    s_star = trainer.network.summary_net(x_star)\n",
    "    s_star_prime = trainer.network.summary_net(x_star_prime)\n",
    "    \n",
    "    MMD_H0 = np.empty(n_simulations)\n",
    "    \n",
    "    for k in tqdm(range(n_simulations)):\n",
    "        MMD_H0[k] = float(maximum_mean_discrepancy(s_star, s_star_prime[np.newaxis, k, ...], unbiased=True))\n",
    "    \n",
    "    if plot:\n",
    "        sns.kdeplot(MMD_H0)\n",
    "    \n",
    "    return MMD_H0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MMD_H0 = MMD_H0_single_instance(trainer, n_simulations=1000, n_obs=T_germany, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"data/MMD_power/MMD_H0.npy\", MMD_H0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MMD_power_analysis(x_star, x_test, MMD_H0, alpha=.05):\n",
    "    n_test = x_test.shape[0]\n",
    "    n_star = x_star.shape[0]\n",
    "\n",
    "    s_test = trainer.network.summary_net(x_test)\n",
    "    s_star = trainer.network.summary_net(x_star)\n",
    "\n",
    "    MMDs_test = np.empty(n_test)\n",
    "\n",
    "    for i in tqdm(range(n_test)):\n",
    "        MMDs_test[i] = float(maximum_mean_discrepancy(s_star, s_test[np.newaxis, i, ...], unbiased=True))\n",
    "\n",
    "    MMD_critical = np.quantile(MMD_H0, 1-alpha)    \n",
    "    power = (MMDs_test > MMD_critical).mean()       \n",
    "        \n",
    "    return power, MMDs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, x_star = trainer._forward_inference(1000, T_germany)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#power_1, MMDs_single_1 = MMD_power_analysis(x_star, x_1, MMD_H0, alpha=.05)\n",
    "#power_2, MMDs_single_2 = MMD_power_analysis(x_star, x_2, MMD_H0, alpha=.05)\n",
    "#power_3, MMDs_single_3 = MMD_power_analysis(x_star, x_3, MMD_H0, alpha=.05)\n",
    "#power_4, MMDs_single_4 = MMD_power_analysis(x_star, x_4, MMD_H0, alpha=.05)\n",
    "\n",
    "#np.save(\"data/MMD_power/MMDs_single_1.npy\", MMDs_single_1)\n",
    "#np.save(\"data/MMD_power/MMDs_single_2.npy\", MMDs_single_2)\n",
    "#np.save(\"data/MMD_power/MMDs_single_3.npy\", MMDs_single_3)\n",
    "#np.save(\"data/MMD_power/MMDs_single_4.npy\", MMDs_single_4)\n",
    "\n",
    "#np.save(\"data/MMD_power/power_1.npy\", power_1)\n",
    "#np.save(\"data/MMD_power/power_2.npy\", power_2)\n",
    "#np.save(\"data/MMD_power/power_3.npy\", power_3)\n",
    "#np.save(\"data/MMD_power/power_4.npy\", power_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MMDs_single_1 = np.load(\"data/MMD_power/MMDs_single_1.npy\")\n",
    "MMDs_single_2 = np.load(\"data/MMD_power/MMDs_single_2.npy\")\n",
    "MMDs_single_3 = np.load(\"data/MMD_power/MMDs_single_3.npy\")\n",
    "MMDs_single_4 = np.load(\"data/MMD_power/MMDs_single_4.npy\")\n",
    "\n",
    "power_1 = np.load(\"data/MMD_power/power_1.npy\")\n",
    "power_2 = np.load(\"data/MMD_power/power_2.npy\")\n",
    "power_3 = np.load(\"data/MMD_power/power_3.npy\")\n",
    "power_4 = np.load(\"data/MMD_power/power_4.npy\")\n",
    "\n",
    "for i, power in enumerate([power_1, power_2, power_3, power_4], 1):\n",
    "    print(f\"M{i}: {power:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = .05\n",
    "\n",
    "model_names = [r\"$\\mathcal{M}^*$\", r\"$\\mathcal{M}_1$\", r\"$\\mathcal{M}_2$\", r\"$\\mathcal{M}_3$\"]\n",
    "colors = [\"tab:orange\", \"tab:purple\", \"tab:green\", \"tab:olive\"]\n",
    "MMDs_singles = [MMDs_single_1, MMDs_single_2, MMDs_single_3, MMDs_single_4]\n",
    "\n",
    "MMD_critical = np.quantile(MMD_H0, 1-alpha)  \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.kdeplot(MMD_H0, linewidth=7, label=r\"$H_0$\")\n",
    "for i in range(4):\n",
    "    sns.kdeplot(MMDs_singles[i], ax=ax, label=model_names[i], color=colors[i])\n",
    "    ax.set_title(r\"Power analysis\")\n",
    "    ax.set_xlabel(r\"$\\widehat{MMD}^2_u$\")\n",
    "ax.axvline(x=MMD_critical, color=\"firebrick\", linewidth=2, linestyle=\"dashed\", label=r\"$\\alpha=5\\%$\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen_star = data_gen\n",
    "from covid_models.covid19_ablation_intervention import data_gen as data_gen_1\n",
    "from covid_models.covid19_ablation_observation import data_gen as data_gen_2\n",
    "from covid_models.covid19_ablation_carrier import data_gen as data_gen_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MMD_power_analysis_generic(G_star, N_star, G_test, N_test, summary_network, number_power_simulations, number_H0_simulations=1000, n_obs=None, alpha=.05):\n",
    "    # Calculate MMD_H0: Simulate MMD(A|B) with A~G_star and B~G_star\n",
    "    MMD_H0 = np.empty(number_H0_simulations)\n",
    "    _, x_star = G_star(N_star, n_obs)\n",
    "    s_star = summary_network(x_star)\n",
    "    for i in tqdm(range(number_H0_simulations), desc=\"Compute MMD under H0\"):\n",
    "        _, x_star_prime = G_star(N_test, n_obs)\n",
    "        s_star_prime = summary_network(x_star_prime)\n",
    "        MMD_H0[i] = float(maximum_mean_discrepancy(s_star, s_star_prime, unbiased=True))\n",
    "    \n",
    "    \n",
    "    # Simulate data from the test model and compare its MMDs against H0 MMD disto\n",
    "    MMDs_test = np.empty(number_power_simulations)\n",
    "    _, x_star = G_star(N_star, n_obs)\n",
    "    s_star = summary_network(x_star)\n",
    "    for i in tqdm(range(number_power_simulations), desc=\"Simulate data from G_test and compute MMD\"):\n",
    "        _, x_test = G_test(N_test, n_obs)\n",
    "        s_test = summary_network(x_test)\n",
    "        \n",
    "        MMDs_test[i] = float(maximum_mean_discrepancy(s_star, s_test, unbiased=True))\n",
    "\n",
    "    MMD_critical = np.quantile(MMD_H0, 1-alpha)    \n",
    "    power = (MMDs_test > MMD_critical).mean()      \n",
    "\n",
    "    return {\"power\" : power,\n",
    "            \"MMD_H0\" : MMD_H0,\n",
    "            \"MMDs_test\" : MMDs_test,\n",
    "            \"MMD_critical\" : MMD_critical,\n",
    "            \"alpha\" : alpha,\n",
    "            \"N\" : N_test\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_star = 1000\n",
    "N_test = 1\n",
    "number_power_simulations = 1000\n",
    "number_H0_simulations = 1000\n",
    "\n",
    "models = [1, 2, 3]\n",
    "for model in models:\n",
    "    print(f\"Power analysis for model {model}\")\n",
    "    data_gen = globals()[f\"data_gen_{model}\"]\n",
    "    power_result = MMD_power_analysis_generic(\n",
    "        G_star = trainer._forward_inference,\n",
    "        N_star = N_star,\n",
    "        G_test = data_gen,\n",
    "        N_test = N_test,\n",
    "        summary_network = trainer.network.summary_net,\n",
    "        number_power_simulations = number_power_simulations,\n",
    "        number_H0_simulations = number_H0_simulations,\n",
    "        n_obs = T_germany\n",
    "        )\n",
    "    \n",
    "    with open(f\"data/COVID_power/covid_power_N{N_test}_M{model}.pkl\", 'wb') as f:\n",
    "        pickle.dump(power_result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_star = 1000\n",
    "N_test = 10\n",
    "number_power_simulations = 1000\n",
    "number_H0_simulations = 1000\n",
    "\n",
    "models = [1, 2, 3]\n",
    "for model in models:\n",
    "    print(f\"Power analysis for model {model}\")\n",
    "    data_gen = globals()[f\"data_gen_{model}\"]\n",
    "    power_result = MMD_power_analysis_generic(\n",
    "        G_star = trainer._forward_inference,\n",
    "        N_star = N_star,\n",
    "        G_test = data_gen,\n",
    "        N_test = N_test,\n",
    "        summary_network = trainer.network.summary_net,\n",
    "        number_power_simulations = number_power_simulations,\n",
    "        number_H0_simulations = number_H0_simulations,\n",
    "        n_obs = T_germany\n",
    "        )\n",
    "    \n",
    "    with open(f\"data/COVID_power/covid_power_N{N_test}_M{model}.pkl\", 'wb') as f:\n",
    "        pickle.dump(power_result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_star = 1000\n",
    "N_test = 2\n",
    "number_power_simulations = 1000\n",
    "number_H0_simulations = 1000\n",
    "\n",
    "models = [1, 2, 3]\n",
    "for model in models:\n",
    "    print(f\"Power analysis for model {model}\")\n",
    "    data_gen = globals()[f\"data_gen_{model}\"]\n",
    "    power_result = MMD_power_analysis_generic(\n",
    "        G_star = trainer._forward_inference,\n",
    "        N_star = N_star,\n",
    "        G_test = data_gen,\n",
    "        N_test = N_test,\n",
    "        summary_network = trainer.network.summary_net,\n",
    "        number_power_simulations = number_power_simulations,\n",
    "        number_H0_simulations = number_H0_simulations,\n",
    "        n_obs = T_germany\n",
    "        )\n",
    "    \n",
    "    with open(f\"data/COVID_power/covid_power_N{N_test}_M{model}.pkl\", 'wb') as f:\n",
    "        pickle.dump(power_result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_star = 1000\n",
    "N_test = 5\n",
    "number_power_simulations = 1000\n",
    "number_H0_simulations = 1000\n",
    "\n",
    "models = [1, 2, 3]\n",
    "for model in models:\n",
    "    print(f\"Power analysis for model {model}\")\n",
    "    data_gen = globals()[f\"data_gen_{model}\"]\n",
    "    power_result = MMD_power_analysis_generic(\n",
    "        G_star = trainer._forward_inference,\n",
    "        N_star = N_star,\n",
    "        G_test = data_gen,\n",
    "        N_test = N_test,\n",
    "        summary_network = trainer.network.summary_net,\n",
    "        number_power_simulations = number_power_simulations,\n",
    "        number_H0_simulations = number_H0_simulations,\n",
    "        n_obs = T_germany\n",
    "        )\n",
    "    \n",
    "    with open(f\"data/COVID_power/covid_power_N{N_test}_M{model}.pkl\", 'wb') as f:\n",
    "        pickle.dump(power_result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_star = 1000\n",
    "N_test = 100\n",
    "number_power_simulations = 1000\n",
    "number_H0_simulations = 1000\n",
    "\n",
    "models = [1, 2, 3]\n",
    "for model in models:\n",
    "    print(f\"Power analysis for model {model}\")\n",
    "    data_gen = globals()[f\"data_gen_{model}\"]\n",
    "    power_result = MMD_power_analysis_generic(\n",
    "        G_star = trainer._forward_inference,\n",
    "        N_star = N_star,\n",
    "        G_test = data_gen,\n",
    "        N_test = N_test,\n",
    "        summary_network = trainer.network.summary_net,\n",
    "        number_power_simulations = number_power_simulations,\n",
    "        number_H0_simulations = number_H0_simulations,\n",
    "        n_obs = T_germany\n",
    "        )\n",
    "    \n",
    "    with open(f\"data/COVID_power/covid_power_N{N_test}_M{model}.pkl\", 'wb') as f:\n",
    "        pickle.dump(power_result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_powers(N_test, models=[1,2,3]):\n",
    "    for model in models:\n",
    "        with open(f\"data/COVID_power/covid_power_N{N_test}_M{model}.pkl\", \"rb\") as f:\n",
    "            power_result = pickle.load(f)\n",
    "\n",
    "        MMD_H0 = power_result[\"MMD_H0\"]\n",
    "        MMDs_test = power_result[\"MMDs_test\"]\n",
    "        MMD_critical = power_result[\"MMD_critical\"]\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(8,4))\n",
    "        sns.histplot(MMD_H0, linewidth=3, label=r\"$H_0$\", color=\"royalblue\")\n",
    "        sns.histplot(MMDs_test, ax=ax, linewidth=3, label=r\"$\\mathcal{M}_{\\mathrm{test}}$\", color=\"seagreen\")\n",
    "        ax.set_title(r'Model $\\mathcal{M}_%d$ ; $1-\\beta=%.3f, N_{test}=%d$'%(model, power_result[\"power\"], N_test))\n",
    "        ax.set_xlabel(r\"$\\widehat{\\mathrm{MMD}}^2_u$\")\n",
    "        ax.axvline(x=MMD_critical, color=\"firebrick\", linewidth=2, linestyle=\"dashed\", label=r\"$\\alpha$\")\n",
    "        ax.legend()\n",
    "        plt.savefig(f\"plots/COVID_power_N{N_test}_M{model}.{FILEFORMAT}\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_powers(N_test=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_powers(N_test=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_powers(N_test=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_powers(N_test=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Data w.r.t. $MMD|H_0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed_cases_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
    "recovered_cases_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv'\n",
    "dead_cases_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv'\n",
    "\n",
    "\n",
    "confirmed_cases = pd.read_csv(confirmed_cases_url, sep=',')\n",
    "recovered_cases = pd.read_csv(recovered_cases_url, sep=',')\n",
    "dead_cases = pd.read_csv(dead_cases_url, sep=',')\n",
    "\n",
    "\n",
    "date_data_begin = datetime.date(2020,3,1)\n",
    "date_data_end = datetime.date(2020,5,21)\n",
    "\n",
    "\n",
    "format_date = lambda date_py: '{}/{}/{}'.format(date_py.month, date_py.day,\n",
    "                                                 str(date_py.year)[2:4])\n",
    "date_formatted_begin = format_date(date_data_begin)\n",
    "date_formatted_end = format_date(date_data_end)\n",
    "\n",
    "cases_obs =  np.array(\n",
    "    confirmed_cases.loc[confirmed_cases[\"Country/Region\"] == \"Germany\", \n",
    "                        date_formatted_begin:date_formatted_end])[0]\n",
    "recovered_obs =  np.array(\n",
    "    recovered_cases.loc[recovered_cases[\"Country/Region\"] == \"Germany\", \n",
    "                        date_formatted_begin:date_formatted_end])[0]\n",
    "\n",
    "dead_obs =  np.array(\n",
    "    dead_cases.loc[dead_cases[\"Country/Region\"] == \"Germany\", \n",
    "                        date_formatted_begin:date_formatted_end])[0]\n",
    "\n",
    "data_germany = np.stack([cases_obs, recovered_obs, dead_obs]).T\n",
    "data_germany = np.diff(data_germany, axis=0)\n",
    "T_germany = data_germany.shape[0]\n",
    "N_germany = 83e6\n",
    "mean_g = np.mean(data_germany, axis=0)\n",
    "std_g = np.std(data_germany, axis=0)\n",
    "\n",
    "data_germany_tensor = data_germany[np.newaxis, ...]\n",
    "data_germany_tensor.shape\n",
    "data_germany_standardized = (data_germany_tensor - mean_g) / std_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2b/8y9y73_n68s56n14hpgpqrt80000gn/T/ipykernel_2318/2154401848.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mMMD_H0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_H0_simulations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_star\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG_star\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_star\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_obs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0ms_star\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummary_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_star\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/bf/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/2b/8y9y73_n68s56n14hpgpqrt80000gn/T/ipykernel_2318/2646937244.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, **args)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mx_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet_I\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mx_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet_R\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mx_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet_D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/bf/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/2b/8y9y73_n68s56n14hpgpqrt80000gn/T/ipykernel_2318/2646937244.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, **args)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/bf/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/bf/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/bf/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m   1264\u001b[0m                 **gpu_lstm_kwargs)\n\u001b[1;32m   1265\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1266\u001b[0;31m             last_output, outputs, new_h, new_c, runtime = standard_lstm(\n\u001b[0m\u001b[1;32m   1267\u001b[0m                 **normal_lstm_kwargs)\n\u001b[1;32m   1268\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/bf/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mstandard_lstm\u001b[0;34m(inputs, init_h, init_c, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths, zero_output_for_mask)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m   last_output, outputs, new_states = K.rnn(\n\u001b[0m\u001b[1;32m   1393\u001b[0m       \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m       \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minit_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_c\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/bf/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/bf/lib/python3.8/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mrnn\u001b[0;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask)\u001b[0m\n\u001b[1;32m   4491\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_ta_t\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4493\u001b[0;31m       final_outputs = control_flow_ops.while_loop(\n\u001b[0m\u001b[1;32m   4494\u001b[0m           \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4495\u001b[0m           \u001b[0mloop_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_ta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/bf/lib/python3.8/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2733\u001b[0m                                               list(loop_vars))\n\u001b[1;32m   2734\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2735\u001b[0;31m         \u001b[0mloop_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2736\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtry_to_pack\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_basetuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2737\u001b[0m           \u001b[0mpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/bf/lib/python3.8/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(time, output_ta_t, *states)\u001b[0m\n\u001b[1;32m   4477\u001b[0m         \u001b[0mcurrent_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mta\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_ta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4478\u001b[0m         \u001b[0mcurrent_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4479\u001b[0;31m         output, new_states = step_function(current_input,\n\u001b[0m\u001b[1;32m   4480\u001b[0m                                            tuple(states) + tuple(constants))\n\u001b[1;32m   4481\u001b[0m         \u001b[0mflat_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/bf/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(cell_inputs, cell_states)\u001b[0m\n\u001b[1;32m   1384\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1386\u001b[0;31m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mc_tm1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1387\u001b[0m     \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/bf/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1162\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1164\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1165\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m         \u001b[0;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/bf/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/bf/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_add_dispatch\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/bf/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36madd_v2\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    466\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m    469\u001b[0m         _ctx, \"AddV2\", name, x, y)\n\u001b[1;32m    470\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_obs = T_germany\n",
    "N_star = 1000\n",
    "N_test = 1\n",
    "number_H0_simulations = 10000\n",
    "G_star = data_gen_star\n",
    "summary_network = trainer.network.summary_net\n",
    "\n",
    "# Calculate MMD_H0: Simulate MMD(A|B) with A~G_star and B~G_star\n",
    "MMD_H0 = np.empty(number_H0_simulations)\n",
    "_, x_star = G_star(N_star, n_obs)\n",
    "s_star = summary_network(x_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in tqdm(range(number_H0_simulations), desc=\"Compute MMD under H0\"):\n",
    "    _, x_star_prime = G_star(N_test, n_obs)\n",
    "    s_star_prime = summary_network(x_star_prime)\n",
    "    MMD_H0[i] = float(maximum_mean_discrepancy(s_star, s_star_prime, unbiased=True))\n",
    "    \n",
    "np.save(\"data/COVID_real_world_analysis/MMD_H0_N1.npy\", MMD_H0)\n",
    "np.save(\"data/COVID_real_world_analysis/MMD_H0_N1_x_star.npy\", x_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"data/COVID_real_world_analysis/MMD_H0_N1_x_star.npy\", x_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_star = np.load(\"data/COVID_real_world_analysis/MMD_H0_N1_x_star.npy\")\n",
    "\n",
    "s_germany_standardized = np.array(trainer.network.summary_net(data_germany_standardized))\n",
    "s_germany_standardized.shape\n",
    "MMD_germany_standardized = float(maximum_mean_discrepancy(s_germany_standardized, s_star, unbiased=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def draw_vline_to_kde(x, kde_object, color, **kwargs):\n",
    "    kde_x, kde_y = kde_object.lines[0].get_data()\n",
    "    idx = np.argmin(np.abs(kde_x - x))\n",
    "    plt.plot([x, x], [0, kde_y[idx]], color=color, linewidth=4, **kwargs)\n",
    "\n",
    "bw_factor = 1.5\n",
    "plt.figure(figsize=(8, 4))\n",
    "alpha = 0.05\n",
    "H0_color = \"#287D8EFF\"\n",
    "data_germany_color = \"#55C667FF\"\n",
    "alpha_color = \"#481567FF\"\n",
    "\n",
    "kde = sns.kdeplot(MMD_H0, fill=False, linewidth=0, bw_adjust=bw_factor)\n",
    "sns.kdeplot(MMD_H0, fill=True, alpha=.12, color = H0_color, bw_adjust=bw_factor)\n",
    "\n",
    "MMD_H0 = np.load(\"data/COVID_real_world_analysis/MMD_H0_N1.npy\")\n",
    "draw_vline_to_kde(MMD_germany_standardized, kde, data_germany_color, label=r\"Germany data\")\n",
    "\n",
    "MMD_critical = np.quantile(MMD_H0, 1-alpha)\n",
    "draw_vline_to_kde(MMD_critical, kde, alpha_color, linestyle=\"dashed\", label=r\"Critical value\")\n",
    "\n",
    "sns.kdeplot(MMD_H0, fill=False, linewidth=3, color = H0_color, label=r\"$H_0$\", bw_adjust=bw_factor)\n",
    "\n",
    "\n",
    "plt.xlabel(r\"$\\widehat{\\mathrm{MMD}}^2_u$\")\n",
    "plt.ylabel(\"\")\n",
    "plt.yticks([])\n",
    "\n",
    "plt.legend(fontsize=20)\n",
    "sns.despine()\n",
    "plt.savefig(f\"plots/COVID_real_data_MMD_H0.{FILEFORMAT}\", bbox_inches=\"tight\", dpi=DPI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
